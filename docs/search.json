[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Siddhartha Sumant Mysore",
    "section": "",
    "text": "SiddharthAAA Mysore"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nYour Name\n\n\nJun 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nHomework 4\n\n\n\n\n\n\nSiddhartha Sumant Mysore\n\n\nJun 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Model\n\n\n\n\n\n\nSiddhartha Sumant Mysore\n\n\nMay 28, 2025\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nSiddhartha Sumant Mysore\n\n\nMay 7, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/Project_1/index.html",
    "href": "blog/Project_1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data.\n\n\n\nI analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt;\n    ggplot(aes(x = wt, y = mpg)) +\n    geom_point()"
  },
  {
    "objectID": "blog/Project_1/index.html#section-1-data",
    "href": "blog/Project_1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data."
  },
  {
    "objectID": "blog/Project_1/index.html#section-2-analysis",
    "href": "blog/Project_1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt;\n    ggplot(aes(x = wt, y = mpg)) +\n    geom_point()"
  },
  {
    "objectID": "blog/AB_Testing/index1.html",
    "href": "blog/AB_Testing/index1.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/AB_Testing/index1.html#introduction",
    "href": "blog/AB_Testing/index1.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/AB_Testing/index1.html#data",
    "href": "blog/AB_Testing/index1.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\n\n\n\n\n\nDescription\n\n\n\n\n\n\nlibrary(haven)\n\n# Load the data from the current working directory\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\nlist.files()\n\n[1] \"index1_files\"         \"index1.qmd\"           \"index1.rmarkdown\"    \n[4] \"karlan_list_2007.dta\"\n\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\n\n\n\n\n#_todo: Read the data into R/Python and describe the data_\n## Load libraries\nlibrary(haven)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Read the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# View structure of the dataset\nstr(data)\n\ntibble [50,083 × 51] (S3: tbl_df/tbl/data.frame)\n $ treatment         : num [1:50083] 0 0 1 1 1 0 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Treatment\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ control           : num [1:50083] 1 1 0 0 0 1 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Control\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ratio             : dbl+lbl [1:50083] 0, 0, 1, 1, 1, 0, 1, 2, 2, 1, 1, 2, 0, 2, 0, 1, 3, 3...\n   ..@ label       : chr \"Match ratio\"\n   ..@ format.stata: chr \"%9.0g\"\n   ..@ labels      : Named num 0\n   .. ..- attr(*, \"names\")= chr \"Control\"\n $ ratio2            : num [1:50083] 0 0 0 0 0 0 0 1 1 0 ...\n  ..- attr(*, \"label\")= chr \"2:1 match ratio\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ratio3            : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"3:1 match ratio\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ size              : dbl+lbl [1:50083] 0, 0, 3, 4, 2, 0, 1, 3, 4, 1, 4, 2, 0, 1, 0, 4, 1, 4...\n   ..@ label       : chr \"Match threshold\"\n   ..@ format.stata: chr \"%9.0g\"\n   ..@ labels      : Named num [1:5] 0 1 2 3 4\n   .. ..- attr(*, \"names\")= chr [1:5] \"Control\" \"$25,000\" \"$50,000\" \"$100,000\" ...\n $ size25            : num [1:50083] 0 0 0 0 0 0 1 0 0 1 ...\n  ..- attr(*, \"label\")= chr \"$25,000 match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ size50            : num [1:50083] 0 0 0 0 1 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"$50,000 match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ size100           : num [1:50083] 0 0 1 0 0 0 0 1 0 0 ...\n  ..- attr(*, \"label\")= chr \"$100,000 match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ sizeno            : num [1:50083] 0 0 0 1 0 0 0 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"Unstated match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ask               : dbl+lbl [1:50083] 0, 0, 1, 1, 1, 0, 3, 3, 2, 2, 1, 3, 0, 2, 0, 1, 2, 3...\n   ..@ label       : chr \"Suggested donation amount\"\n   ..@ format.stata: chr \"%9.0g\"\n   ..@ labels      : Named num [1:4] 0 1 2 3\n   .. ..- attr(*, \"names\")= chr [1:4] \"Control\" \"1x\" \"1.25x\" \"1.50x\"\n $ askd1             : num [1:50083] 0 0 1 1 1 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Suggested donation was highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ askd2             : num [1:50083] 0 0 0 0 0 0 0 0 1 1 ...\n  ..- attr(*, \"label\")= chr \"Suggested donation was 1.25 x highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ askd3             : num [1:50083] 0 0 0 0 0 0 1 1 0 0 ...\n  ..- attr(*, \"label\")= chr \"Suggested donation was 1.50 x highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ask1              : num [1:50083] 55 25 55 55 35 95 125 75 250 150 ...\n  ..- attr(*, \"label\")= chr \"Highest previous contribution (for suggestion)\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ ask2              : num [1:50083] 70 35 70 70 45 120 160 95 315 190 ...\n  ..- attr(*, \"label\")= chr \"1.25 x highest previous contribution (for suggestion)\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ ask3              : num [1:50083] 85 50 85 85 55 145 190 120 375 225 ...\n  ..- attr(*, \"label\")= chr \"1.50 x highest previous contribution (for suggestion)\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ amount            : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Dollars given\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2f\"\n $ gave              : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Gave anything\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ amountchange      : num [1:50083] -45 -25 -50 -25 -15 -45 -50 -65 -100 -125 ...\n  ..- attr(*, \"label\")= chr \"Change in amount given\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2fc\"\n $ hpa               : num [1:50083] 45 25 50 50 25 90 100 65 200 125 ...\n  ..- attr(*, \"label\")= chr \"Highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2fc\"\n $ ltmedmra          : num [1:50083] 0 1 0 1 1 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Small prior donor: last gift was less than median $35\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ freq              : num [1:50083] 2 2 3 15 42 20 12 13 28 4 ...\n  ..- attr(*, \"label\")= chr \"Number of prior donations\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ years             : num [1:50083] 4 3 2 8 95 10 8 16 19 7 ...\n  ..- attr(*, \"label\")= chr \"Number of years since initial donation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ year5             : num [1:50083] 0 0 0 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"At least 5 years since initial donation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ mrm2              : num [1:50083] 31 5 6 1 24 3 4 4 6 35 ...\n  ..- attr(*, \"label\")= chr \"Number of months since last donation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ dormant           : num [1:50083] 1 0 0 0 1 0 0 0 0 1 ...\n  ..- attr(*, \"label\")= chr \"Already donated in 2005\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ female            : num [1:50083] 0 0 0 0 1 0 1 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Female\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ couple            : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Couple\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ state50one        : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"State tag: 1 for one observation of each of 50 states; 0 otherwise\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ nonlit            : num [1:50083] 5 0 3 1 1 0 0 4 1 4 ...\n  ..- attr(*, \"label\")= chr \"Nonlitigation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ cases             : num [1:50083] 4 2 1 2 1 0 1 3 1 3 ...\n  ..- attr(*, \"label\")= chr \"Court cases from state in 2004-5 in which organization was involved\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ statecnt          : num [1:50083] 4.5 2.98 9.61 3.28 2.3 ...\n  ..- attr(*, \"label\")= chr \"Percent of sample from state\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2f\"\n $ stateresponse     : num [1:50083] 0.0199 0.0261 0.023 0.0207 0.0156 ...\n  ..- attr(*, \"label\")= chr \"Proportion of sample from the state who gave\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ stateresponset    : num [1:50083] 0.0195 0.0278 0.0222 0.0247 0.017 ...\n  ..- attr(*, \"label\")= chr \"Proportion of treated sample from the state who gave\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ stateresponsec    : num [1:50083] 0.0208 0.0225 0.0247 0.0127 0.0129 ...\n  ..- attr(*, \"label\")= chr \"Proportion of control sample from the state who gave\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ stateresponsetminc: num [1:50083] -0.0013 0.00534 -0.00258 0.01202 0.00408 ...\n  ..- attr(*, \"label\")= chr \"stateresponset - stateresponsec\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ perbush           : num [1:50083] 0.49 0.465 0.408 0.465 0.525 ...\n  ..- attr(*, \"label\")= chr \"State vote share for Bush\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ close25           : num [1:50083] 1 0 0 0 0 1 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"State vote share for Bush between 47.5% and 52.5%\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ red0              : num [1:50083] 0 0 0 0 1 1 1 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"Red state\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ blue0             : num [1:50083] 1 1 1 1 0 0 0 1 0 1 ...\n  ..- attr(*, \"label\")= chr \"Blue state\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ redcty            : num [1:50083] 0 1 0 1 0 1 1 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"Red county\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ bluecty           : num [1:50083] 1 0 1 0 1 0 0 1 0 1 ...\n  ..- attr(*, \"label\")= chr \"Blue county\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ pwhite            : num [1:50083] 0.446 NA 0.936 0.888 0.759 ...\n  ..- attr(*, \"label\")= chr \"Proportion white within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ pblack            : num [1:50083] 0.5278 NA 0.0119 0.0108 0.1274 ...\n  ..- attr(*, \"label\")= chr \"Proportion black within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ page18_39         : num [1:50083] 0.318 NA 0.276 0.279 0.442 ...\n  ..- attr(*, \"label\")= chr \"Proportion age 18-39 within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ ave_hh_sz         : num [1:50083] 2.1 NA 2.48 2.65 1.85 ...\n  ..- attr(*, \"label\")= chr \"Average household size within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2f\"\n $ median_hhincome   : num [1:50083] 28517 NA 51175 79269 40908 ...\n  ..- attr(*, \"label\")= chr \"Median household income within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ powner            : num [1:50083] 0.5 NA 0.722 0.92 0.416 ...\n  ..- attr(*, \"label\")= chr \"Proportion house owner within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ psch_atlstba      : num [1:50083] 0.325 NA 0.193 0.412 0.44 ...\n  ..- attr(*, \"label\")= chr \"Proportion who finished college within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ pop_propurban     : num [1:50083] 1 NA 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Proportion of population urban within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n\ndata %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(\n    response_rate = mean(gave),\n    avg_donation = mean(amount),\n    n = n()\n  )\n\n# A tibble: 2 × 4\n  treatment response_rate avg_donation     n\n      &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n1         0        0.0179        0.813 16687\n2         1        0.0220        0.967 33396\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\n\n\n\n\nBalance Test\n\n\n\n\n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n# Load required libraries\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Variables to test\nvars &lt;- c(\"mrm2\", \"freq\", \"years\")\n\n# Loop through each variable and perform t-test and regression\nfor (var in vars) {\n  cat(\"\\n==============================\\n\")\n  cat(\"Variable:\", var, \"\\n\")\n\n  # Remove missing values\n  df_clean &lt;- na.omit(data[, c(var, \"treatment\")])\n\n  # T-test\n  t_test &lt;- t.test(df_clean[[var]] ~ df_clean$treatment, var.equal = FALSE)\n  print(t_test)\n\n  # Linear regression\n  formula &lt;- as.formula(paste(var, \"~ treatment\"))\n  lm_model &lt;- lm(formula, data = df_clean)\n  print(summary(lm_model))\n}\n\n\n==============================\nVariable: mrm2 \n\n    Welch Two Sample t-test\n\ndata:  df_clean[[var]] by df_clean$treatment\nt = -0.11953, df = 33394, p-value = 0.9049\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.2381015  0.2107298\nsample estimates:\nmean in group 0 mean in group 1 \n       12.99814        13.01183 \n\n\nCall:\nlm(formula = formula, data = df_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.012  -9.012  -5.012   6.002 154.988 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.99814    0.09353 138.979   &lt;2e-16 ***\ntreatment    0.01369    0.11453   0.119    0.905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.08 on 50080 degrees of freedom\nMultiple R-squared:  2.851e-07, Adjusted R-squared:  -1.968e-05 \nF-statistic: 0.01428 on 1 and 50080 DF,  p-value: 0.9049\n\n\n==============================\nVariable: freq \n\n    Welch Two Sample t-test\n\ndata:  df_clean[[var]] by df_clean$treatment\nt = 0.11085, df = 33326, p-value = 0.9117\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.1998370  0.2237945\nsample estimates:\nmean in group 0 mean in group 1 \n       8.047342        8.035364 \n\n\nCall:\nlm(formula = formula, data = df_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n -8.035  -6.047  -4.035   1.953 209.965 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.04734    0.08821  91.231   &lt;2e-16 ***\ntreatment   -0.01198    0.10802  -0.111    0.912    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.39 on 50081 degrees of freedom\nMultiple R-squared:  2.455e-07, Adjusted R-squared:  -1.972e-05 \nF-statistic: 0.0123 on 1 and 50081 DF,  p-value: 0.9117\n\n\n==============================\nVariable: years \n\n    Welch Two Sample t-test\n\ndata:  df_clean[[var]] by df_clean$treatment\nt = 1.0909, df = 32401, p-value = 0.2753\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.04584866  0.16094698\nsample estimates:\nmean in group 0 mean in group 1 \n       6.135914        6.078365 \n\n\nCall:\nlm(formula = formula, data = df_clean)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.136 -4.136 -1.136  2.864 88.922 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.13591    0.04260 144.023   &lt;2e-16 ***\ntreatment   -0.05755    0.05217  -1.103     0.27    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.503 on 50080 degrees of freedom\nMultiple R-squared:  2.429e-05, Adjusted R-squared:  4.327e-06 \nF-statistic: 1.217 on 1 and 50080 DF,  p-value: 0.27\n\n\nTable 1 shows that the treatment and control groups were balanced on key baseline characteristics. That’s important because: 1. It confirms that random assignment worked. 2. It rules out the possibility that observed treatment effects are due to pre-existing differences.\n\n\n\n\n\n\n\n\n\nExperimental Results\n\n\n\n\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Load necessary libraries\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Calculate donation proportions\ndonation_props &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(prop_donated = mean(gave, na.rm = TRUE)) %&gt;%\n  mutate(group = ifelse(treatment == 1, \"Treatment\", \"Control\"))\n\n# Plot\nggplot(donation_props, aes(x = group, y = prop_donated, fill = group)) +\n  geom_bar(stat = \"identity\", width = 0.6, show.legend = FALSE) +\n  geom_text(aes(label = scales::percent(prop_donated, accuracy = 0.1)), \n            vjust = -0.5, size = 5) +\n  scale_fill_manual(values = c(\"Control\" = \"#87CEEB\", \"Treatment\" = \"#1E90FF\")) +\n  labs(\n    title = \"Proportion of People Who Donated\",\n    x = \"Group\",\n    y = \"Proportion Donated\"\n  ) +\n  scale_y_continuous(labels = scales::percent, limits = c(0, 0.05)) +  # Set limit if values are small\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 12),\n    axis.title = element_text(size = 14)\n  )\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Drop missing values\ndata_clean &lt;- na.omit(data[, c(\"gave\", \"treatment\")])\n\n# T-test\nt_test_result &lt;- t.test(gave ~ treatment, data = data_clean, var.equal = FALSE)\nprint(t_test_result)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by treatment\nt = -3.2095, df = 36577, p-value = 0.001331\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.006733310 -0.001627399\nsample estimates:\nmean in group 0 mean in group 1 \n     0.01785821      0.02203857 \n\n# Bivariate linear regression\nlm_result &lt;- lm(gave ~ treatment, data = data_clean)\nsummary(lm_result)\n\n\nCall:\nlm(formula = gave ~ treatment, data = data_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\n\nThe coefficient on treatment is the marginal effect (in latent index units) of being in the treatment group.\nA positive, significant coefficient supports the claim that the treatment increased the likelihood of donating.\n\n\n# Load necessary libraries\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Drop missing values for the relevant variables\ndata_clean &lt;- na.omit(data[, c(\"gave\", \"treatment\")])\n\n# Run the probit regression\nprobit_model &lt;- glm(gave ~ treatment, family = binomial(link = \"probit\"), data = data_clean)\n\n# View the summary\nsummary(probit_model)\n\n\nCall:\nglm(formula = gave ~ treatment, family = binomial(link = \"probit\"), \n    data = data_clean)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.10014    0.02332 -90.074  &lt; 2e-16 ***\ntreatment    0.08678    0.02788   3.113  0.00185 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nThe treatment effect is positive and statistically significant (p ≈ 0.0019).\nThis supports Table 3, Column 1 of the paper: being assigned to treatment increases the probability of donating — in latent terms.\nThe latent index increase of 0.087 suggests a meaningful shift in underlying propensity to donate.\n\n\n\n\n\n\n\n\n\n\nDifferences between Match Rates\n\n\n\n\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Filter to only treatment group and relevant variables\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# Create subsets by match ratio\ngave_1to1 &lt;- subset(data_match, ratio == 1)$gave\ngave_2to1 &lt;- subset(data_match, ratio == 2)$gave\ngave_3to1 &lt;- subset(data_match, ratio == 3)$gave\n\n# T-tests\nt_test_2vs1 &lt;- t.test(gave_2to1, gave_1to1, var.equal = FALSE)\nt_test_3vs1 &lt;- t.test(gave_3to1, gave_1to1, var.equal = FALSE)\n\n# Print results\nt_test_2vs1\n\n\n    Welch Two Sample t-test\n\ndata:  gave_2to1 and gave_1to1\nt = 0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001942773  0.005711275\nsample estimates:\n mean of x  mean of y \n0.02263338 0.02074912 \n\nt_test_3vs1\n\n\n    Welch Two Sample t-test\n\ndata:  gave_3to1 and gave_1to1\nt = 1.015, df = 22215, p-value = 0.3101\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001847501  0.005816051\nsample estimates:\n mean of x  mean of y \n0.02273340 0.02074912 \n\n\nThis supports the authors comment 1. The existence of a match offer boosts giving. 2. But increasing the generosity of the match (from 1:1 to 2:1 or 3:1) doesn’t significantly change donor behavior.\n\n# Load required library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Filter treatment group and non-missing values\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# Create dummy variables for match ratios\ndata_match$ratio1 &lt;- ifelse(data_match$ratio == 1, 1, 0)\ndata_match$ratio2 &lt;- ifelse(data_match$ratio == 2, 1, 0)\ndata_match$ratio3 &lt;- ifelse(data_match$ratio == 3, 1, 0)\n\n# Option 1: Regression using dummy variables\nmodel_dummies &lt;- lm(gave ~ ratio1 + ratio2 + ratio3, data = data_match)\nsummary(model_dummies)\n\n\nCall:\nlm(formula = gave ~ ratio1 + ratio2 + ratio3, data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients: (1 not defined because of singularities)\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.022733   0.001392  16.335   &lt;2e-16 ***\nratio1      -0.001984   0.001968  -1.008    0.313    \nratio2      -0.000100   0.001968  -0.051    0.959    \nratio3             NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n# Option 2: Regression using ratio as a categorical variable\nmodel_categorical &lt;- lm(gave ~ factor(ratio), data = data_match)\nsummary(model_categorical)\n\n\nCall:\nlm(formula = gave ~ factor(ratio), data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.020749   0.001391  14.912   &lt;2e-16 ***\nfactor(ratio)2 0.001884   0.001968   0.958    0.338    \nfactor(ratio)3 0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n\n\nThe treatment group gave slightly more on average than the control group.\nHowever, the p-value (0.055) is just above the conventional 0.05 threshold for statistical significance.\nThis means that we can’t confidently say that treatment caused people to donate more — the observed difference could be due to chance.\n\n\n# Load the data\nlibrary(haven)\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to treatment group with non-missing values\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# 1. Raw response rate differences\nresponse_rates &lt;- tapply(data_match$gave, data_match$ratio, mean)\ndiff_2vs1_raw &lt;- response_rates[\"2\"] - response_rates[\"1\"]\ndiff_3vs2_raw &lt;- response_rates[\"3\"] - response_rates[\"2\"]\n\n# 2. Regression using factor(ratio)\nmodel &lt;- lm(gave ~ factor(ratio), data = data_match)\nsummary(model)\n\n\nCall:\nlm(formula = gave ~ factor(ratio), data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.020749   0.001391  14.912   &lt;2e-16 ***\nfactor(ratio)2 0.001884   0.001968   0.958    0.338    \nfactor(ratio)3 0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n# Differences from fitted model (1:1 is reference group)\ncoef_2vs1 &lt;- coef(model)[\"factor(ratio)2\"]\ncoef_3vs1 &lt;- coef(model)[\"factor(ratio)3\"]\ncoef_3vs2 &lt;- coef_3vs1 - coef_2vs1\n\n# Print everything\nprint(response_rates)\n\n         1          2          3 \n0.02074912 0.02263338 0.02273340 \n\ncat(\"Raw Diff 2:1 - 1:1 =\", diff_2vs1_raw, \"\\n\")\n\nRaw Diff 2:1 - 1:1 = 0.001884251 \n\ncat(\"Raw Diff 3:1 - 2:1 =\", diff_3vs2_raw, \"\\n\")\n\nRaw Diff 3:1 - 2:1 = 0.000100024 \n\ncat(\"Fitted Diff 2:1 - 1:1 =\", coef_2vs1, \"\\n\")\n\nFitted Diff 2:1 - 1:1 = 0.001884251 \n\ncat(\"Fitted Diff 3:1 - 2:1 =\", coef_3vs2, \"\\n\")\n\nFitted Diff 3:1 - 2:1 = 0.000100024 \n\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\n\n\n\n\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Drop missing values\ndata_clean &lt;- na.omit(data[, c(\"amount\", \"treatment\")])\n\n# T-test\nt_test_result &lt;- t.test(amount ~ treatment, data = data_clean, var.equal = FALSE)\nprint(t_test_result)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = -1.9183, df = 36216, p-value = 0.05509\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.310555423  0.003344493\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8132678       0.9668733 \n\n# Bivariate linear regression\nlm_result &lt;- lm(amount ~ treatment, data = data_clean)\nsummary(lm_result)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data_clean)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n\n\nThe mean donation in the treatment group is slightly higher than in the control group (~$0.15 more). 2.But the p-value from both tests is just above 0.05, which means the difference is not statistically significant at the 95% confidence level.\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to donors only (amount &gt; 0)\ndata_donors &lt;- subset(data, amount &gt; 0 & !is.na(treatment))\n\n# T-test\nt_test_donors &lt;- t.test(amount ~ treatment, data = data_donors, var.equal = FALSE)\nprint(t_test_donors)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = 0.58461, df = 557.46, p-value = 0.559\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -3.937240  7.274027\nsample estimates:\nmean in group 0 mean in group 1 \n       45.54027        43.87188 \n\n# Linear regression (donation amount ~ treatment)\nlm_donors &lt;- lm(amount ~ treatment, data = data_donors)\nsummary(lm_donors)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data_donors)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n\n\nThe t-test and linear regression both likely returned a non-significant difference in donation amounts between the treatment and control groups.\nThe regression coefficient for treatment was probably close to 0 or negative, and not statistically significant.\n\n\n# Load necessary library\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only those who donated\ndata_donors &lt;- subset(data, amount &gt; 0 & !is.na(treatment))\n\n# Calculate group means\ngroup_means &lt;- data_donors %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(mean_amount = mean(amount))\n\n# Plot for Treatment group\nggplot(data_donors[data_donors$treatment == 1, ], aes(x = amount)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\") +\n  geom_vline(xintercept = group_means$mean_amount[group_means$treatment == 1], \n             color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Donation Amounts - Treatment Group\", x = \"Donation Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Plot for Control group\nggplot(data_donors[data_donors$treatment == 0, ], aes(x = amount)) +\n  geom_histogram(binwidth = 2, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = group_means$mean_amount[group_means$treatment == 0], \n             color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Donation Amounts - Control Group\", x = \"Donation Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\n\n\n\n\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\n\n\n\n\n\n\n\nLaw of Large Numbers\n\n\n\n\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only positive donations\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Simulate: 100,000 draws from control, 10,000 from treatment\nsim_control &lt;- sample(donations_control, size = 100000, replace = TRUE)\nsim_treatment &lt;- sample(donations_treatment, size = 10000, replace = TRUE)\n\n# Sample 10,000 control values to match treatment sample\nsim_control_sample &lt;- sample(sim_control, size = 10000, replace = FALSE)\n\n# Calculate differences\ndifferences &lt;- sim_treatment - sim_control_sample\n\n# Cumulative average\ncumulative_avg_diff &lt;- cumsum(differences) / seq_along(differences)\n\n# True difference in means\ntrue_diff &lt;- mean(donations_treatment) - mean(donations_control)\n\n# Plot\nplot(cumulative_avg_diff, type = \"l\", col = \"blue\", lwd = 2,\n     main = \"Cumulative Average of Simulated Differences\",\n     xlab = \"Simulation Index\", ylab = \"Cumulative Average Difference\")\nabline(h = true_diff, col = \"red\", lty = 2)\nlegend(\"bottomright\", legend = c(\"Cumulative Average\", \"True Difference\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\n\n\n\n\n\n\n\n\nYes — the cumulative average approaches the true difference in means. This illustrates the Law of Large Numbers: with more data, your estimate becomes more stable and closer to the true population value. It also reinforces the power of randomization and repeated sampling — even if individual draws are noisy, the average across many replicates becomes reliable.\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to positive donation amounts\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Function to simulate 1000 average differences at a given sample size\nsimulate_diffs &lt;- function(n, reps = 1000) {\n  replicate(reps, {\n    sample_control &lt;- sample(donations_control, size = n, replace = TRUE)\n    sample_treat &lt;- sample(donations_treatment, size = n, replace = TRUE)\n    mean(sample_treat) - mean(sample_control)\n  })\n}\n\n# Sample sizes to test\nsample_sizes &lt;- c(50, 200, 500, 1000)\ndiffs_list &lt;- lapply(sample_sizes, simulate_diffs)\n\n# Plot the histograms\npar(mfrow = c(2, 2))  # 2x2 layout\nfor (i in 1:4) {\n  hist(diffs_list[[i]], main = paste(\"Sample Size =\", sample_sizes[i]),\n       xlab = \"Avg Difference (Treatment - Control)\", col = \"skyblue\", border = \"black\")\n  abline(v = 0, col = \"red\", lwd = 2, lty = 2)\n}\n\n\n\n\n\n\n\n\nAt small sample sizes (e.g., 50):\nThe distribution of average differences is wide and noisy. The red line at zero often appears in the middle — suggesting a high chance of not detecting a difference. As sample size increases (200 → 500 → 1000):\nThe distribution becomes narrower. It starts to center away from zero, and zero moves to the tail of the distribution. This reflects increasing statistical power — you’re more likely to detect the true effect as the sample grows.\n\n\n\n#Done"
  },
  {
    "objectID": "blog/AB_Testing/index1.html#experimental-results",
    "href": "blog/AB_Testing/index1.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\n\n\n\n\n\nCharitable Contribution Made\n\n\n\n\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Load necessary libraries\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Calculate donation proportions\ndonation_props &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(prop_donated = mean(gave, na.rm = TRUE)) %&gt;%\n  mutate(group = ifelse(treatment == 1, \"Treatment\", \"Control\"))\n\n# Plot\nggplot(donation_props, aes(x = group, y = prop_donated, fill = group)) +\n  geom_bar(stat = \"identity\", width = 0.6, show.legend = FALSE) +\n  geom_text(aes(label = scales::percent(prop_donated, accuracy = 0.1)), \n            vjust = -0.5, size = 5) +\n  scale_fill_manual(values = c(\"Control\" = \"#87CEEB\", \"Treatment\" = \"#1E90FF\")) +\n  labs(\n    title = \"Proportion of People Who Donated\",\n    x = \"Group\",\n    y = \"Proportion Donated\"\n  ) +\n  scale_y_continuous(labels = scales::percent, limits = c(0, 0.05)) +  # Set limit if values are small\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 12),\n    axis.title = element_text(size = 14)\n  )\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Drop missing values\ndata_clean &lt;- na.omit(data[, c(\"gave\", \"treatment\")])\n\n# T-test\nt_test_result &lt;- t.test(gave ~ treatment, data = data_clean, var.equal = FALSE)\nprint(t_test_result)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by treatment\nt = -3.2095, df = 36577, p-value = 0.001331\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.006733310 -0.001627399\nsample estimates:\nmean in group 0 mean in group 1 \n     0.01785821      0.02203857 \n\n# Bivariate linear regression\nlm_result &lt;- lm(gave ~ treatment, data = data_clean)\nsummary(lm_result)\n\n\nCall:\nlm(formula = gave ~ treatment, data = data_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\n\nThe coefficient on treatment is the marginal effect (in latent index units) of being in the treatment group.\nA positive, significant coefficient supports the claim that the treatment increased the likelihood of donating.\n\n\n# Load necessary libraries\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Drop missing values for the relevant variables\ndata_clean &lt;- na.omit(data[, c(\"gave\", \"treatment\")])\n\n# Run the probit regression\nprobit_model &lt;- glm(gave ~ treatment, family = binomial(link = \"probit\"), data = data_clean)\n\n# View the summary\nsummary(probit_model)\n\n\nCall:\nglm(formula = gave ~ treatment, family = binomial(link = \"probit\"), \n    data = data_clean)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.10014    0.02332 -90.074  &lt; 2e-16 ***\ntreatment    0.08678    0.02788   3.113  0.00185 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nThe treatment effect is positive and statistically significant (p ≈ 0.0019).\nThis supports Table 3, Column 1 of the paper: being assigned to treatment increases the probability of donating — in latent terms.\nThe latent index increase of 0.087 suggests a meaningful shift in underlying propensity to donate.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Filter to only treatment group and relevant variables\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# Create subsets by match ratio\ngave_1to1 &lt;- subset(data_match, ratio == 1)$gave\ngave_2to1 &lt;- subset(data_match, ratio == 2)$gave\ngave_3to1 &lt;- subset(data_match, ratio == 3)$gave\n\n# T-tests\nt_test_2vs1 &lt;- t.test(gave_2to1, gave_1to1, var.equal = FALSE)\nt_test_3vs1 &lt;- t.test(gave_3to1, gave_1to1, var.equal = FALSE)\n\n# Print results\nt_test_2vs1\n\n\n    Welch Two Sample t-test\n\ndata:  gave_2to1 and gave_1to1\nt = 0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001942773  0.005711275\nsample estimates:\n mean of x  mean of y \n0.02263338 0.02074912 \n\nt_test_3vs1\n\n\n    Welch Two Sample t-test\n\ndata:  gave_3to1 and gave_1to1\nt = 1.015, df = 22215, p-value = 0.3101\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001847501  0.005816051\nsample estimates:\n mean of x  mean of y \n0.02273340 0.02074912 \n\n\nThis supports the authors comment 1. The existence of a match offer boosts giving. 2. But increasing the generosity of the match (from 1:1 to 2:1 or 3:1) doesn’t significantly change donor behavior.\n\n# Load required library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Filter treatment group and non-missing values\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# Create dummy variables for match ratios\ndata_match$ratio1 &lt;- ifelse(data_match$ratio == 1, 1, 0)\ndata_match$ratio2 &lt;- ifelse(data_match$ratio == 2, 1, 0)\ndata_match$ratio3 &lt;- ifelse(data_match$ratio == 3, 1, 0)\n\n# Option 1: Regression using dummy variables\nmodel_dummies &lt;- lm(gave ~ ratio1 + ratio2 + ratio3, data = data_match)\nsummary(model_dummies)\n\n\nCall:\nlm(formula = gave ~ ratio1 + ratio2 + ratio3, data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients: (1 not defined because of singularities)\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.022733   0.001392  16.335   &lt;2e-16 ***\nratio1      -0.001984   0.001968  -1.008    0.313    \nratio2      -0.000100   0.001968  -0.051    0.959    \nratio3             NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n# Option 2: Regression using ratio as a categorical variable\nmodel_categorical &lt;- lm(gave ~ factor(ratio), data = data_match)\nsummary(model_categorical)\n\n\nCall:\nlm(formula = gave ~ factor(ratio), data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.020749   0.001391  14.912   &lt;2e-16 ***\nfactor(ratio)2 0.001884   0.001968   0.958    0.338    \nfactor(ratio)3 0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n\n\nThe treatment group gave slightly more on average than the control group.\nHowever, the p-value (0.055) is just above the conventional 0.05 threshold for statistical significance.\nThis means that we can’t confidently say that treatment caused people to donate more — the observed difference could be due to chance.\n\n\n# Load the data\nlibrary(haven)\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to treatment group with non-missing values\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# 1. Raw response rate differences\nresponse_rates &lt;- tapply(data_match$gave, data_match$ratio, mean)\ndiff_2vs1_raw &lt;- response_rates[\"2\"] - response_rates[\"1\"]\ndiff_3vs2_raw &lt;- response_rates[\"3\"] - response_rates[\"2\"]\n\n# 2. Regression using factor(ratio)\nmodel &lt;- lm(gave ~ factor(ratio), data = data_match)\nsummary(model)\n\n\nCall:\nlm(formula = gave ~ factor(ratio), data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.020749   0.001391  14.912   &lt;2e-16 ***\nfactor(ratio)2 0.001884   0.001968   0.958    0.338    \nfactor(ratio)3 0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n# Differences from fitted model (1:1 is reference group)\ncoef_2vs1 &lt;- coef(model)[\"factor(ratio)2\"]\ncoef_3vs1 &lt;- coef(model)[\"factor(ratio)3\"]\ncoef_3vs2 &lt;- coef_3vs1 - coef_2vs1\n\n# Print everything\nprint(response_rates)\n\n         1          2          3 \n0.02074912 0.02263338 0.02273340 \n\ncat(\"Raw Diff 2:1 - 1:1 =\", diff_2vs1_raw, \"\\n\")\n\nRaw Diff 2:1 - 1:1 = 0.001884251 \n\ncat(\"Raw Diff 3:1 - 2:1 =\", diff_3vs2_raw, \"\\n\")\n\nRaw Diff 3:1 - 2:1 = 0.000100024 \n\ncat(\"Fitted Diff 2:1 - 1:1 =\", coef_2vs1, \"\\n\")\n\nFitted Diff 2:1 - 1:1 = 0.001884251 \n\ncat(\"Fitted Diff 3:1 - 2:1 =\", coef_3vs2, \"\\n\")\n\nFitted Diff 3:1 - 2:1 = 0.000100024 \n\n\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\n\n\n\n\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Drop missing values\ndata_clean &lt;- na.omit(data[, c(\"amount\", \"treatment\")])\n\n# T-test\nt_test_result &lt;- t.test(amount ~ treatment, data = data_clean, var.equal = FALSE)\nprint(t_test_result)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = -1.9183, df = 36216, p-value = 0.05509\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.310555423  0.003344493\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8132678       0.9668733 \n\n# Bivariate linear regression\nlm_result &lt;- lm(amount ~ treatment, data = data_clean)\nsummary(lm_result)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data_clean)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n\n\nThe mean donation in the treatment group is slightly higher than in the control group (~$0.15 more). 2.But the p-value from both tests is just above 0.05, which means the difference is not statistically significant at the 95% confidence level.\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to donors only (amount &gt; 0)\ndata_donors &lt;- subset(data, amount &gt; 0 & !is.na(treatment))\n\n# T-test\nt_test_donors &lt;- t.test(amount ~ treatment, data = data_donors, var.equal = FALSE)\nprint(t_test_donors)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = 0.58461, df = 557.46, p-value = 0.559\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -3.937240  7.274027\nsample estimates:\nmean in group 0 mean in group 1 \n       45.54027        43.87188 \n\n# Linear regression (donation amount ~ treatment)\nlm_donors &lt;- lm(amount ~ treatment, data = data_donors)\nsummary(lm_donors)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data_donors)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n\n\nThe t-test and linear regression both likely returned a non-significant difference in donation amounts between the treatment and control groups.\nThe regression coefficient for treatment was probably close to 0 or negative, and not statistically significant.\n\n\n# Load necessary library\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only those who donated\ndata_donors &lt;- subset(data, amount &gt; 0 & !is.na(treatment))\n\n# Calculate group means\ngroup_means &lt;- data_donors %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(mean_amount = mean(amount))\n\n# Plot for Treatment group\nggplot(data_donors[data_donors$treatment == 1, ], aes(x = amount)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\") +\n  geom_vline(xintercept = group_means$mean_amount[group_means$treatment == 1], \n             color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Donation Amounts - Treatment Group\", x = \"Donation Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Plot for Control group\nggplot(data_donors[data_donors$treatment == 0, ], aes(x = amount)) +\n  geom_histogram(binwidth = 2, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = group_means$mean_amount[group_means$treatment == 0], \n             color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Donation Amounts - Control Group\", x = \"Donation Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\n\n\n\n\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\n\n\n\n\n\n\n\nLaw of Large Numbers\n\n\n\n\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only positive donations\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Simulate: 100,000 draws from control, 10,000 from treatment\nsim_control &lt;- sample(donations_control, size = 100000, replace = TRUE)\nsim_treatment &lt;- sample(donations_treatment, size = 10000, replace = TRUE)\n\n# Sample 10,000 control values to match treatment sample\nsim_control_sample &lt;- sample(sim_control, size = 10000, replace = FALSE)\n\n# Calculate differences\ndifferences &lt;- sim_treatment - sim_control_sample\n\n# Cumulative average\ncumulative_avg_diff &lt;- cumsum(differences) / seq_along(differences)\n\n# True difference in means\ntrue_diff &lt;- mean(donations_treatment) - mean(donations_control)\n\n# Plot\nplot(cumulative_avg_diff, type = \"l\", col = \"blue\", lwd = 2,\n     main = \"Cumulative Average of Simulated Differences\",\n     xlab = \"Simulation Index\", ylab = \"Cumulative Average Difference\")\nabline(h = true_diff, col = \"red\", lty = 2)\nlegend(\"bottomright\", legend = c(\"Cumulative Average\", \"True Difference\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\n\n\n\n\n\n\n\n\nYes — the cumulative average approaches the true difference in means. This illustrates the Law of Large Numbers: with more data, your estimate becomes more stable and closer to the true population value. It also reinforces the power of randomization and repeated sampling — even if individual draws are noisy, the average across many replicates becomes reliable.\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to positive donation amounts\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Function to simulate 1000 average differences at a given sample size\nsimulate_diffs &lt;- function(n, reps = 1000) {\n  replicate(reps, {\n    sample_control &lt;- sample(donations_control, size = n, replace = TRUE)\n    sample_treat &lt;- sample(donations_treatment, size = n, replace = TRUE)\n    mean(sample_treat) - mean(sample_control)\n  })\n}\n\n# Sample sizes to test\nsample_sizes &lt;- c(50, 200, 500, 1000)\ndiffs_list &lt;- lapply(sample_sizes, simulate_diffs)\n\n# Plot the histograms\npar(mfrow = c(2, 2))  # 2x2 layout\nfor (i in 1:4) {\n  hist(diffs_list[[i]], main = paste(\"Sample Size =\", sample_sizes[i]),\n       xlab = \"Avg Difference (Treatment - Control)\", col = \"skyblue\", border = \"black\")\n  abline(v = 0, col = \"red\", lwd = 2, lty = 2)\n}\n\n\n\n\n\n\n\n\nAt small sample sizes (e.g., 50):\nThe distribution of average differences is wide and noisy. The red line at zero often appears in the middle — suggesting a high chance of not detecting a difference. As sample size increases (200 → 500 → 1000):\nThe distribution becomes narrower. It starts to center away from zero, and zero moves to the tail of the distribution. This reflects increasing statistical power — you’re more likely to detect the true effect as the sample grows."
  },
  {
    "objectID": "blog/AB_Testing/index1.html#simulation-experiment",
    "href": "blog/AB_Testing/index1.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only positive donations\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Simulate: 100,000 draws from control, 10,000 from treatment\nsim_control &lt;- sample(donations_control, size = 100000, replace = TRUE)\nsim_treatment &lt;- sample(donations_treatment, size = 10000, replace = TRUE)\n\n# Sample 10,000 control values to match treatment sample\nsim_control_sample &lt;- sample(sim_control, size = 10000, replace = FALSE)\n\n# Calculate differences\ndifferences &lt;- sim_treatment - sim_control_sample\n\n# Cumulative average\ncumulative_avg_diff &lt;- cumsum(differences) / seq_along(differences)\n\n# True difference in means\ntrue_diff &lt;- mean(donations_treatment) - mean(donations_control)\n\n# Plot\nplot(cumulative_avg_diff, type = \"l\", col = \"blue\", lwd = 2,\n     main = \"Cumulative Average of Simulated Differences\",\n     xlab = \"Simulation Index\", ylab = \"Cumulative Average Difference\")\nabline(h = true_diff, col = \"red\", lty = 2)\nlegend(\"bottomright\", legend = c(\"Cumulative Average\", \"True Difference\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\n\n\n\n\n\n\n\n\nYes — the cumulative average approaches the true difference in means. This illustrates the Law of Large Numbers: with more data, your estimate becomes more stable and closer to the true population value. It also reinforces the power of randomization and repeated sampling — even if individual draws are noisy, the average across many replicates becomes reliable.\n\n\nCentral Limit Theorem\n\n# Load necessary library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to positive donation amounts\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Function to simulate 1000 average differences at a given sample size\nsimulate_diffs &lt;- function(n, reps = 1000) {\n  replicate(reps, {\n    sample_control &lt;- sample(donations_control, size = n, replace = TRUE)\n    sample_treat &lt;- sample(donations_treatment, size = n, replace = TRUE)\n    mean(sample_treat) - mean(sample_control)\n  })\n}\n\n# Sample sizes to test\nsample_sizes &lt;- c(50, 200, 500, 1000)\ndiffs_list &lt;- lapply(sample_sizes, simulate_diffs)\n\n# Plot the histograms\npar(mfrow = c(2, 2))  # 2x2 layout\nfor (i in 1:4) {\n  hist(diffs_list[[i]], main = paste(\"Sample Size =\", sample_sizes[i]),\n       xlab = \"Avg Difference (Treatment - Control)\", col = \"skyblue\", border = \"black\")\n  abline(v = 0, col = \"red\", lwd = 2, lty = 2)\n}\n\n\n\n\n\n\n\n\nAt small sample sizes (e.g., 50):\nThe distribution of average differences is wide and noisy. The red line at zero often appears in the middle — suggesting a high chance of not detecting a difference. As sample size increases (200 → 500 → 1000):\nThe distribution becomes narrower. It starts to center away from zero, and zero moves to the tail of the distribution. This reflects increasing statistical power — you’re more likely to detect the true effect as the sample grows."
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html",
    "href": "blog/Homework_2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n# Load necessary library\nlibrary(readr)\n\n# Read in the Blueprinty dataset\nblueprinty &lt;- read_csv(\"/Users/siddharthamysore/sid_site/blog/Homework_2/blueprinty.csv\")\nairbnb &lt;- read_csv(\"/Users/siddharthamysore/sid_site/blog/Homework_2/airbnb.csv\") \n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\n\n# Create a labeled version of customer status for readability\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(customer_status = ifelse(iscustomer == 1, \"Customer\", \"Non-customer\"))\n\n# Prettier histogram\nggplot(blueprinty, aes(x = patents, fill = customer_status)) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"white\", alpha = 0.85) +\n  scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\")) +\n  labs(\n    title = \"Distribution of Patent Counts by Customer Status\",\n    x = \"Number of Patents (Last 5 Years)\",\n    y = \"Number of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)\n\n# Load the data\nblueprinty &lt;- read.csv(\"blueprinty.csv\")\n\n# Calculate mean patents by customer status\ngrouped_means &lt;- blueprinty %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_patents = round(mean(patents, na.rm = TRUE), 2))\n\n# Pretty table output\nkable(grouped_means, col.names = c(\"Customer Status\", \"Mean Patents\"))\n\n\n\n\nCustomer Status\nMean Patents\n\n\n\n\n0\n3.47\n\n\n1\n4.13"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#blueprinty-case-study",
    "href": "blog/Homework_2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n# Load necessary library\nlibrary(readr)\n\n# Read in the Blueprinty dataset\nblueprinty &lt;- read_csv(\"/Users/siddharthamysore/sid_site/blog/Homework_2/blueprinty.csv\")\nairbnb &lt;- read_csv(\"/Users/siddharthamysore/sid_site/blog/Homework_2/airbnb.csv\") \n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\n\n# Create a labeled version of customer status for readability\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(customer_status = ifelse(iscustomer == 1, \"Customer\", \"Non-customer\"))\n\n# Prettier histogram\nggplot(blueprinty, aes(x = patents, fill = customer_status)) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"white\", alpha = 0.85) +\n  scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\")) +\n  labs(\n    title = \"Distribution of Patent Counts by Customer Status\",\n    x = \"Number of Patents (Last 5 Years)\",\n    y = \"Number of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)\n\n# Load the data\nblueprinty &lt;- read.csv(\"blueprinty.csv\")\n\n# Calculate mean patents by customer status\ngrouped_means &lt;- blueprinty %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_patents = round(mean(patents, na.rm = TRUE), 2))\n\n# Pretty table output\nkable(grouped_means, col.names = c(\"Customer Status\", \"Mean Patents\"))\n\n\n\n\nCustomer Status\nMean Patents\n\n\n\n\n0\n3.47\n\n\n1\n4.13"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#airbnb-case-study",
    "href": "blog/Homework_2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#observation",
    "href": "blog/Homework_2/hw2_questions.html#observation",
    "title": "Poisson Regression Examples",
    "section": "Observation:",
    "text": "Observation:\n\nCustomers tend to have more patents: Firms using Blueprinty are more frequently found in the 4–6 patent range, while non-customers cluster around 2–4 patents.\nVisual difference is clear: The histogram shows a visible rightward shift in patent counts for customers compared to non-customers.\nCaution is needed: This difference could be influenced by other factors like firm age or region, not just Blueprinty usage.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Part A: Region distribution by customer status\nblueprinty %&gt;%\n  mutate(customer_status = ifelse(iscustomer == 1, \"Customer\", \"Non-customer\")) %&gt;%\n  count(region, customer_status) %&gt;%\n  ggplot(aes(x = region, y = n, fill = customer_status)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\")) +\n  labs(title = \"Region Distribution by Customer Status\",\n       x = \"Region\",\n       y = \"Number of Firms\",\n       fill = \"Customer Status\") +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n\n\n\n\n\n\n# Part B: Age comparison by customer status\nggplot(blueprinty, aes(x = factor(iscustomer, labels = c(\"Non-customer\", \"Customer\")), y = age, fill = factor(iscustomer))) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\")) +\n  labs(title = \"Firm Age by Customer Status\",\n       x = \"Customer Status\",\n       y = \"Firm Age (Years)\",\n       fill = \"Customer Status\") +\n  theme_minimal(base_size = 14) +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n\n\n\n\n\n\n# Mean age by customer status\nblueprinty %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_age = mean(age)) %&gt;%\n  mutate(Customer_Status = ifelse(iscustomer == 1, \"Customer\", \"Non-customer\"))\n\n# A tibble: 2 × 3\n  iscustomer mean_age Customer_Status\n       &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1          0     26.1 Non-customer   \n2          1     26.9 Customer"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#observation-1",
    "href": "blog/Homework_2/hw2_questions.html#observation-1",
    "title": "Poisson Regression Examples",
    "section": "Observation",
    "text": "Observation\n\nRegional differences: Customers are more concentrated in the Northeast region, indicating that Blueprinty’s adoption varies by geography and may be influenced by regional factors such as innovation density or marketing reach.\nAge differences: Customers tend to be slightly older firms on average, which may affect both their patenting behavior and their likelihood of adopting Blueprinty’s software.\n\n\nEstimation of Simple Poisson Model\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nLikelihood for Poisson Distribution\nLet ( Y_1, Y_2, , Y_n ) be independent observations from a Poisson distribution with mean ( ). The likelihood function is:\n\\[\nL(\\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!} = e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#log-likelihood-for-poisson-function",
    "href": "blog/Homework_2/hw2_questions.html#log-likelihood-for-poisson-function",
    "title": "Poisson Regression Examples",
    "section": "Log likelihood for Poisson Function",
    "text": "Log likelihood for Poisson Function\n\n# Define the log-likelihood function for Poisson\npoisson_log_likelihood &lt;- function(lambda, Y) {\n  n &lt;- length(Y)\n  sum_Y &lt;- sum(Y)\n  logL &lt;- -n * lambda + sum_Y * log(lambda) - sum(lgamma(Y + 1))\n  return(logL)\n}\n\n\nlibrary(ggplot2)\n\n# Define the log-likelihood function\npoisson_log_likelihood &lt;- function(lambda, Y) {\n  n &lt;- length(Y)\n  sum_Y &lt;- sum(Y)\n  logL &lt;- -n * lambda + sum_Y * log(lambda) - sum(lgamma(Y + 1))\n  return(logL)\n}\n\n# Generate values of lambda\nlambda_vals &lt;- seq(1, 7, by = 0.1)\n\n# Compute log-likelihood values\nloglik_vals &lt;- sapply(lambda_vals, function(l) poisson_log_likelihood(lambda = l, Y = blueprinty$patents))\n\n# Create a data frame for plotting\nll_df &lt;- data.frame(\n  lambda = lambda_vals,\n  loglik = loglik_vals\n)\n\n# Find the lambda that maximizes the log-likelihood\nmle_lambda &lt;- lambda_vals[which.max(loglik_vals)]\n\n# Prettier ggplot version\nggplot(ll_df, aes(x = lambda, y = loglik)) +\n  geom_line(color = \"#1f77b4\", size = 1.2) +\n  geom_vline(xintercept = mle_lambda, linetype = \"dashed\", color = \"red\", size = 1) +\n  labs(\n    title = \"Log-Likelihood of Poisson Model\",\n    subtitle = paste(\"Maximum at λ ≈\", round(mle_lambda, 2)),\n    x = expression(lambda),\n    y = \"Log-Likelihood\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\nDeriving the MLE for the Poisson Model\nLet ( Y_1, Y_2, , Y_n ) be independent observations where ( Y_i () ). The log-likelihood function is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^n \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n= -n\\lambda + \\left( \\sum_{i=1}^n Y_i \\right) \\log \\lambda - \\sum_{i=1}^n \\log(Y_i!)\n\\]\nTake the derivative with respect to ( ) and set it equal to zero:\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = -n + \\frac{1}{\\lambda} \\sum_{i=1}^n Y_i = 0\n\\]\nSolving for ( ):\n\\[\n-n + \\frac{1}{\\lambda} \\sum_{i=1}^n Y_i = 0\n\\quad \\Rightarrow \\quad\n\\lambda = \\frac{1}{n} \\sum_{i=1}^n Y_i = \\bar{Y}\n\\]\nConclusion: The maximum likelihood estimate of ( ) is the sample mean ( {Y} ), which makes intuitive sense because the Poisson distribution’s mean is ( ).\n\n\nNumerically Estimating λ using optim()\n\n# Negative log-likelihood (since optim() minimizes)\nneg_log_likelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(Inf)  # avoid log(0) or negative lambda\n  -poisson_log_likelihood(lambda, Y)\n}\n\n# Run optimization\noptim_result &lt;- optim(\n  par = 2,  # initial guess for lambda\n  fn = neg_log_likelihood,\n  Y = blueprinty$patents,\n  method = \"Brent\",\n  lower = 0.01,\n  upper = 10\n)\n\n# Display MLE of lambda\noptim_result$par\n\n[1] 3.684667\n\n\n\n\nEstimation of Poisson Regression Model\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nLog-Likelihood for Poisson Regression Model\n\n# Poisson regression log-likelihood function\npoisson_regression_loglik &lt;- function(beta, Y, X) {\n  eta &lt;- X %*% beta                 # linear predictor\n  lambda &lt;- exp(eta)               # inverse link: exp\n  logL &lt;- sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n  return(logL)\n}\n\n\n\nEstimate Poisson Regression Coefficients with optim()\n\nlibrary(dplyr)\n\n# 1. Prepare design matrix X and response Y\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(\n    age2 = age^2,\n    region = factor(region),  # Ensure it's a factor\n    region = relevel(region, ref = \"Southwest\")  # Reference category\n  )\n\n# Create model matrix: intercept, age, age^2, region dummies, customer\nX &lt;- model.matrix(~ age + age2 + region + iscustomer, data = blueprinty)\nY &lt;- blueprinty$patents\n\n# 2. Define negative log-likelihood function for use in optim()\nneg_loglik &lt;- function(beta, Y, X) {\n  eta &lt;- X %*% beta\n  lambda &lt;- exp(eta)\n  -sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n}\n\n# 3. Estimate beta using optim()\ninit_beta &lt;- rep(0, ncol(X))  # Start with zeros\nfit &lt;- optim(\n  par = init_beta,\n  fn = neg_loglik,\n  Y = Y,\n  X = X,\n  method = \"BFGS\",\n  hessian = TRUE\n)\n\n# 4. Extract coefficients and standard errors\nbeta_hat &lt;- fit$par\nhessian &lt;- fit$hessian\nse &lt;- sqrt(diag(solve(hessian)))  # Invert Hessian to get variance-covariance\n\n# 5. Create and display a table of results\n\n\n# Load knitr for pretty tables\nlibrary(knitr)\n\n# Create and print nicely formatted coefficient table\ncoef_table &lt;- data.frame(\n  Term = colnames(X),\n  Estimate = round(beta_hat, 4),\n  Std_Error = round(se, 4)\n)\n\nkable(coef_table, caption = \"Poisson Regression Coefficients and Standard Errors\")\n\n\nPoisson Regression Coefficients and Standard Errors\n\n\nTerm\nEstimate\nStd_Error\n\n\n\n\n(Intercept)\n-0.1257\n0.1108\n\n\nage\n0.1155\n0.0064\n\n\nage2\n-0.0022\n0.0001\n\n\nregionMidwest\n-0.0234\n0.0472\n\n\nregionNortheast\n-0.0247\n0.0392\n\n\nregionNorthwest\n-0.0349\n0.0498\n\n\nregionSouth\n-0.0055\n0.0494\n\n\niscustomer\n0.0606\n0.0321\n\n\n\n\n\n\n\nVerifying Results with glm()\n\n# Fit Poisson regression using glm()\nglm_model &lt;- glm(\n  patents ~ age + I(age^2) + region + iscustomer,\n  family = poisson(link = \"log\"),\n  data = blueprinty\n)\n\n# Summary of results\nsummary(glm_model)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(link = \"log\"), data = blueprinty)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.458344   0.182720  -2.508   0.0121 *  \nage              0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)        -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionMidwest   -0.050576   0.047198  -1.072   0.2839    \nregionNortheast -0.021406   0.038479  -0.556   0.5780    \nregionNorthwest -0.068151   0.049875  -1.366   0.1718    \nregionSouth      0.005985   0.048741   0.123   0.9023    \niscustomer       0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\nInterpretation of Poisson Regression Results\n\nCustomer Effect: The coefficient for iscustomer is positive, suggesting that firms using Blueprinty’s software have a higher expected number of patents, holding all other variables constant.\nFirm Age: The positive coefficient for age and negative coefficient for age² imply a nonlinear relationship, where patent activity increases with age up to a point, then slightly declines.\nRegional Differences: Some regional coefficients (e.g., Northeast, Midwest) are slightly negative compared to the reference group (Southwest), indicating lower expected patent counts in those regions, although the effects are modest.\nModel Fit: The signs, magnitudes, and standard errors from glm() closely match the custom MLE estimates, validating your implementation.\n\n\n\nEstimating the Effect of Blueprinty’s Software on Patents\n\n# Create counterfactual and treatment versions of the dataset\nX_0 &lt;- blueprinty\nX_0$iscustomer &lt;- 0\n\nX_1 &lt;- blueprinty\nX_1$iscustomer &lt;- 1\n\n# Predict number of patents using fitted glm model\ny_pred_0 &lt;- predict(glm_model, newdata = X_0, type = \"response\")\ny_pred_1 &lt;- predict(glm_model, newdata = X_1, type = \"response\")\n\n# Difference in predicted outcomes\neffect_vec &lt;- y_pred_1 - y_pred_0\naverage_effect &lt;- mean(effect_vec)\n\n# Display average predicted difference\naverage_effect\n\n[1] 0.7927681\n\n\nThe model estimates that using Blueprinty’s software increases the expected number of patents by approximately 0.79 patents per user, on average."
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#airbnb-case-study-modeling-number-of-bookings-via-review-counts",
    "href": "blog/Homework_2/hw2_questions.html#airbnb-case-study-modeling-number-of-bookings-via-review-counts",
    "title": "Poisson Regression Examples",
    "section": "Airbnb Case Study: Modeling Number of Bookings via Review Counts",
    "text": "Airbnb Case Study: Modeling Number of Bookings via Review Counts\n\n# Load Airbnb data\nlibrary(readr)\nlibrary(dplyr)\n\n# Filter to keep relevant variables and drop rows with NAs\nairbnb_clean &lt;- airbnb %&gt;%\n  select(number_of_reviews, room_type, bathrooms, bedrooms, price,\n         review_scores_cleanliness, review_scores_location, \n         review_scores_value, instant_bookable) %&gt;%\n  na.omit()\n\n# Check dimensions after cleaning\ndim(airbnb_clean)\n\n[1] 30160     9\n\n\n\nExploratory Data Analysis\n\nlibrary(ggplot2)\n\n# Distribution of number of reviews\nggplot(airbnb_clean, aes(x = number_of_reviews)) +\n  geom_histogram(binwidth = 5, fill = \"#2c7fb8\", color = \"white\") +\n  labs(title = \"Distribution of Number of Reviews\",\n       x = \"Number of Reviews\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Boxplot of reviews by room type\nggplot(airbnb_clean, aes(x = room_type, y = number_of_reviews)) +\n  geom_boxplot(fill = \"#7fcdbb\") +\n  labs(title = \"Number of Reviews by Room Type\",\n       x = \"Room Type\", y = \"Number of Reviews\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nFit Poisson Regression Model\n\n# Fit Poisson regression model\nairbnb_model &lt;- glm(number_of_reviews ~ room_type + bathrooms + bedrooms +\n                      price + review_scores_cleanliness +\n                      review_scores_location + review_scores_value +\n                      instant_bookable,\n                    data = airbnb_clean, family = poisson(link = \"log\"))\n\n# View summary\nsummary(airbnb_model)\n\n\nCall:\nglm(formula = number_of_reviews ~ room_type + bathrooms + bedrooms + \n    price + review_scores_cleanliness + review_scores_location + \n    review_scores_value + instant_bookable, family = poisson(link = \"log\"), \n    data = airbnb_clean)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                3.572e+00  1.600e-02 223.215  &lt; 2e-16 ***\nroom_typePrivate room     -1.453e-02  2.737e-03  -5.310 1.09e-07 ***\nroom_typeShared room      -2.519e-01  8.618e-03 -29.229  &lt; 2e-16 ***\nbathrooms                 -1.240e-01  3.747e-03 -33.091  &lt; 2e-16 ***\nbedrooms                   7.494e-02  1.988e-03  37.698  &lt; 2e-16 ***\nprice                     -1.436e-05  8.303e-06  -1.729   0.0838 .  \nreview_scores_cleanliness  1.132e-01  1.493e-03  75.821  &lt; 2e-16 ***\nreview_scores_location    -7.680e-02  1.607e-03 -47.796  &lt; 2e-16 ***\nreview_scores_value       -9.153e-02  1.798e-03 -50.902  &lt; 2e-16 ***\ninstant_bookableTRUE       3.344e-01  2.889e-03 115.748  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 961626  on 30159  degrees of freedom\nResidual deviance: 936528  on 30150  degrees of freedom\nAIC: 1058014\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\nInterpretation of Results\n\nRoom Type: Listings that are private or shared rooms receive significantly fewer reviews than entire home/apartments, all else equal.\nBathrooms/Bedrooms: More bathrooms or bedrooms are associated with more reviews, though the effect size is modest.\nPrice: Higher prices are slightly negatively associated with number of reviews.\nReview Scores: Higher cleanliness, location, and value scores are positively associated with review counts, suggesting better guest experiences lead to more bookings.\nInstant Bookable: Listings that are instantly bookable receive more reviews, possibly due to convenience.\n\nThese results reflect how different listing features influence demand as measured by review activity."
  },
  {
    "objectID": "blog/Project_3/hw3_questions.html",
    "href": "blog/Project_3/hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "blog/Project_3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "blog/Project_3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "blog/Project_3/hw3_questions.html#simulate-conjoint-data",
    "href": "blog/Project_3/hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n# set seed for reproducibility\nset.seed(123)\n\n# define attributes\nbrand &lt;- c(\"N\", \"P\", \"H\") # Netflix, Prime, Hulu\nad &lt;- c(\"Yes\", \"No\")\nprice &lt;- seq(8, 32, by=4)\n\n# generate all possible profiles\nprofiles &lt;- expand.grid(\n    brand = brand,\n    ad = ad,\n    price = price\n)\nm &lt;- nrow(profiles)\n\n# assign part-worth utilities (true parameters)\nb_util &lt;- c(N = 1.0, P = 0.5, H = 0)\na_util &lt;- c(Yes = -0.8, No = 0.0)\np_util &lt;- function(p) -0.1 * p\n\n# number of respondents, choice tasks, and alternatives per task\nn_peeps &lt;- 100\nn_tasks &lt;- 10\nn_alts &lt;- 3\n\n# function to simulate one respondent’s data\nsim_one &lt;- function(id) {\n  \n    datlist &lt;- list()\n    \n    # loop over choice tasks\n    for (t in 1:n_tasks) {\n        \n        # randomly sample 3 alts (better practice would be to use a design)\n        dat &lt;- cbind(resp=id, task=t, profiles[sample(m, size=n_alts), ])\n        \n        # compute deterministic portion of utility\n        dat$v &lt;- b_util[dat$brand] + a_util[dat$ad] + p_util(dat$price) |&gt; round(10)\n        \n        # add Gumbel noise (Type I extreme value)\n        dat$e &lt;- -log(-log(runif(n_alts)))\n        dat$u &lt;- dat$v + dat$e\n        \n        # identify chosen alternative\n        dat$choice &lt;- as.integer(dat$u == max(dat$u))\n        \n        # store task\n        datlist[[t]] &lt;- dat\n    }\n    \n    # combine all tasks for one respondent\n    do.call(rbind, datlist)\n}\n\n# simulate data for all respondents\nconjoint_data &lt;- do.call(rbind, lapply(1:n_peeps, sim_one))\n\n# remove values unobservable to the researcher\nconjoint_data &lt;- conjoint_data[ , c(\"resp\", \"task\", \"brand\", \"ad\", \"price\", \"choice\")]\n\n# clean up\nrm(list=setdiff(ls(), \"conjoint_data\"))\n\n\n\n\n\n\n\n\n\n\n3. Preparing the Data for Estimation\n\n\n\n\n\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\n\n# Load necessary library\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Load the data\nconjoint_data &lt;- read.csv(\"/Users/siddharthamysore/sid_site/blog/Project_3/conjoint_data.csv\")\n\n# Inspect data\nhead(conjoint_data)\n\n  resp task choice brand  ad price\n1    1    1      1     N Yes    28\n2    1    1      0     H Yes    16\n3    1    1      0     P Yes    16\n4    1    2      0     N Yes    32\n5    1    2      1     P Yes    16\n6    1    2      0     N Yes    24\n\n# One-hot encode brand and ad (Hulu and No are references)\nconjoint_data &lt;- conjoint_data %&gt;%\n  mutate(\n    brand_N = ifelse(brand == \"N\", 1, 0),\n    brand_P = ifelse(brand == \"P\", 1, 0),\n    ad_yes = ifelse(ad == \"Yes\", 1, 0)\n  )\n\n# Create a numeric respondent-task ID for grouping\nconjoint_data &lt;- conjoint_data %&gt;%\n  mutate(group = paste0(resp, \"_\", task))\n\n# Final design matrix X and outcome y\nX &lt;- conjoint_data %&gt;%\n  select(brand_N, brand_P, ad_yes, price) %&gt;%\n  as.matrix()\n\ny &lt;- conjoint_data$choice\n\n\n\n\n\n\n\n\n\n\n4. Estimation via Maximum Likelihood\n\n\n\n\n\n\nlog_likelihood &lt;- function(beta, X, y, group_ids) {\n  # Convert beta to column matrix\n  beta &lt;- matrix(beta, ncol = 1)\n  \n  # Compute utility\n  utilities &lt;- X %*% beta\n  exp_utilities &lt;- exp(utilities)\n  \n  # Data frame for group-level normalization\n  df &lt;- data.frame(\n    group = group_ids,\n    exp_utilities = exp_utilities,\n    y = y\n  )\n  \n  # Compute denominator for softmax per group\n  df$sum_exp &lt;- ave(df$exp_utilities, df$group, FUN = sum)\n  \n  # Compute probabilities\n  df$prob &lt;- df$exp_utilities / df$sum_exp\n  \n  # Log-likelihood only for chosen alternatives\n  log_lik &lt;- sum(log(df$prob[df$y == 1]))\n  \n  return(-log_lik)  # Negative for minimization\n}\n\n\n# Initial values for optimization\ninitial_beta &lt;- rep(0, 4)\n\n# Group identifiers (resp + task)\ngroup_ids &lt;- paste0(conjoint_data$resp, \"_\", conjoint_data$task)\n\n# Run MLE optimization\nmle &lt;- optim(\n  par = initial_beta,\n  fn = log_likelihood,\n  X = X,\n  y = y,\n  group_ids = group_ids,\n  hessian = TRUE,\n  method = \"BFGS\"\n)\n\n# Extract MLE estimates and compute standard errors\nbeta_hat &lt;- mle$par\nhessian &lt;- mle$hessian\nvcov &lt;- solve(hessian)  # Invert Hessian to get variance-covariance matrix\nse &lt;- sqrt(diag(vcov))  # Standard errors\n\n# Construct 95% confidence intervals\nci_lower &lt;- beta_hat - 1.96 * se\nci_upper &lt;- beta_hat + 1.96 * se\n\n# Compile results\nresults &lt;- data.frame(\n  Estimate = beta_hat,\n  Std_Error = se,\n  CI_Lower = ci_lower,\n  CI_Upper = ci_upper\n)\nrownames(results) &lt;- c(\"Brand_Netflix\", \"Brand_Prime\", \"Ad_Yes\", \"Price\")\n\n# Show the results\nknitr::kable(\n  results,\n  caption = \"Maximum Likelihood Estimates with 95% Confidence Intervals\",\n  digits = 3,\n  align = \"lccc\"\n)\n\n\nMaximum Likelihood Estimates with 95% Confidence Intervals\n\n\n\nEstimate\nStd_Error\nCI_Lower\nCI_Upper\n\n\n\n\nBrand_Netflix\n0.941\n0.111\n0.724\n1.159\n\n\nBrand_Prime\n0.502\n0.111\n0.284\n0.719\n\n\nAd_Yes\n-0.732\n0.088\n-0.904\n-0.560\n\n\nPrice\n-0.099\n0.006\n-0.112\n-0.087\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Estimation via Bayesian Methods\n\n\n\n\n\n\nset.seed(42)\n\n# Log-prior (matches hint: N(0,5) for binary, N(0,1) for price)\nlog_prior &lt;- function(beta) {\n  sum(dnorm(beta[1:3], mean = 0, sd = 5, log = TRUE)) +\n    dnorm(beta[4], mean = 0, sd = 1, log = TRUE)\n}\n\n# Log-posterior = log-likelihood + log-prior\nlog_posterior &lt;- function(beta, X, y, group_ids) {\n  -log_likelihood(beta, X, y, group_ids) + log_prior(beta)\n}\n\n# Metropolis-Hastings MCMC function\nmetropolis_sampler &lt;- function(start, n_iter, X, y, group_ids) {\n  chain &lt;- matrix(NA, nrow = n_iter, ncol = length(start))\n  chain[1, ] &lt;- start\n  \n  # Proposal std devs per dimension\n  proposal_sd &lt;- c(0.05, 0.05, 0.05, 0.005)\n  \n  for (i in 2:n_iter) {\n    current &lt;- chain[i - 1, ]\n    proposal &lt;- rnorm(4, mean = current, sd = proposal_sd)  # diagonal MVN\n    \n    log_alpha &lt;- log_posterior(proposal, X, y, group_ids) -\n                 log_posterior(current, X, y, group_ids)\n    \n    if (log(runif(1)) &lt; log_alpha) {\n      chain[i, ] &lt;- proposal  # accept\n    } else {\n      chain[i, ] &lt;- current  # reject\n    }\n  }\n  \n  colnames(chain) &lt;- c(\"Beta_Netflix\", \"Beta_Prime\", \"Beta_AdYes\", \"Beta_Price\")\n  return(chain)\n}\n\n# Run the MCMC sampler\nmcmc_chain &lt;- metropolis_sampler(\n  start = rep(0, 4),\n  n_iter = 11000,\n  X = X,\n  y = y,\n  group_ids = group_ids\n)\n\n# Drop burn-in: retain final 10,000 draws\nmcmc_post &lt;- mcmc_chain[1001:11000, ]\n\n\n# Extract Beta_Price draws\nbeta_price &lt;- mcmc_post[, \"Beta_Price\"]\n\n# Trace plot\nplot(beta_price, type = \"l\", col = \"blue\",\n     main = \"Trace Plot for Beta_Price\",\n     xlab = \"Iteration\", ylab = \"Value\")\n\n\n\n\n\n\n\n# Histogram of posterior distribution\nhist(beta_price, breaks = 50, col = \"lightblue\",\n     main = \"Posterior Distribution of Beta_Price\",\n     xlab = \"Beta_Price\", probability = TRUE)\n\n# Add density estimate\nlines(density(beta_price), col = \"darkblue\", lwd = 2)\n\n\n\n\n\n\n\n\n\n# Step 1: Posterior summary\nposterior_summary &lt;- apply(mcmc_post, 2, function(draws) {\n  c(\n    Mean = mean(draws),\n    SD = sd(draws),\n    CI_Lower = quantile(draws, 0.025),\n    CI_Upper = quantile(draws, 0.975)\n  )\n}) %&gt;% t() %&gt;% as.data.frame()\n\n# Step 2: MLE summary (from earlier)\nmle_summary &lt;- results[, c(\"Estimate\", \"Std_Error\", \"CI_Lower\", \"CI_Upper\")]\ncolnames(mle_summary) &lt;- c(\"Mean\", \"SD\", \"CI_Lower\", \"CI_Upper\")\n\n# Step 3: Combine into one comparison table\ncomparison &lt;- data.frame(\n  Parameter = rownames(posterior_summary),\n  MLE_Mean = mle_summary$Mean,\n  MLE_SD = mle_summary$SD,\n  MLE_CI_Lower = mle_summary$CI_Lower,\n  MLE_CI_Upper = mle_summary$CI_Upper,\n  Bayes_Mean = posterior_summary$Mean,\n  Bayes_SD = posterior_summary$SD,\n  Bayes_CI_Lower = posterior_summary$CI_Lower,\n  Bayes_CI_Upper = posterior_summary$CI_Upper\n)\n\n# Display comparison\nknitr::kable(\n  comparison,\n  caption = \"Comparison of MLE and Bayesian Estimates with 95% Intervals\",\n  digits = 3,\n  align = \"lccccccc\"\n)\n\n\nComparison of MLE and Bayesian Estimates with 95% Intervals\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMLE_Mean\nMLE_SD\nMLE_CI_Lower\nMLE_CI_Upper\nBayes_Mean\nBayes_SD\nBayes_CI_Lower\nBayes_CI_Upper\n\n\n\n\nBeta_Netflix\n0.941\n0.111\n0.724\n1.159\n0.947\n0.114\n0.731\n1.166\n\n\nBeta_Prime\n0.502\n0.111\n0.284\n0.719\n0.497\n0.116\n0.276\n0.732\n\n\nBeta_AdYes\n-0.732\n0.088\n-0.904\n-0.560\n-0.737\n0.088\n-0.902\n-0.564\n\n\nBeta_Price\n-0.099\n0.006\n-0.112\n-0.087\n-0.100\n0.006\n-0.112\n-0.088\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6. Discussion\n\n\n\n\n\n\nSuppose you did not simulate the data. What do you observe about the parameter estimates?\nIf the data were not simulated, the parameter estimates would reflect actual consumer preferences derived from observed choice behavior. In this case, we would interpret each coefficient as an empirical estimate of how much that feature contributes to the utility of a product. The magnitude and direction of the coefficients would tell us which attributes are most valued by consumers.\nAdditionally, the standard errors or credible intervals would indicate the precision of these estimates, influenced by the sample size, the design of the experiment, and how much variation exists in the attribute levels.\n\n\nWhat does \\(\\beta_\\text{Netflix} &gt; \\beta_\\text{Prime}\\) mean?\nThis means that, all else equal (same price and ad status), consumers derive more utility from Netflix than from Amazon Prime. In other words, Netflix is generally preferred over Prime by the average consumer in the sample. This could reflect brand perception, content quality, or user experience advantages.\n\n\nDoes it make sense that \\(\\beta_\\text{price}\\) is negative?\nYes, this is both expected and logical. A negative coefficient on price indicates that higher prices reduce the utility of a streaming option, which in turn makes it less likely to be chosen. This is consistent with standard economic intuition: consumers prefer lower prices, and demand typically decreases as price increases. The more negative the coefficient, the more price-sensitive the consumers are.\n\n\nSimulating and Estimating a Multi-Level (Hierarchical) Model\nTo simulate data from — and estimate parameters of — a multi-level (random-parameter or hierarchical) model, the key change is to allow individual-level heterogeneity in preferences.\n\n🔄 Simulation Changes\nIn the current setup, every respondent shares the same true β vector (part-worths). In a hierarchical model, each respondent gets their own β drawn from a population distribution:\n\nLet \\(\\beta_i \\sim \\mathcal{N}(\\mu, \\Sigma)\\) for respondent i\nThen, utility becomes \\(U_{ij} = x_{j}'\\beta_i + \\varepsilon_{ij}\\)\n\nTo simulate this: 1. First draw a unique \\(\\beta_i\\) for each individual from the population distribution. 2. Then simulate choices using those respondent-specific betas.\n\n\n📈 Estimation Changes\nIn estimation, a hierarchical Bayes model would: - Place priors on both the individual-level coefficients (\\(\\beta_i\\)) and the hyperparameters (\\(\\mu\\), \\(\\Sigma\\)) - Use MCMC to alternate between drawing: - \\(\\beta_i\\) for each respondent - The population-level parameters (\\(\\mu\\), \\(\\Sigma\\))\nThis allows the model to borrow strength across individuals while capturing preference heterogeneity.\nIn practice, hierarchical MNL models are used in real-world conjoint studies because they: - Improve prediction accuracy - Reflect the true diversity in consumer preferences - Enable targeting and segmentation based on individual-level part-worths"
  },
  {
    "objectID": "blog/Project_3/hw3_questions.html#preparing-the-data-for-estimation",
    "href": "blog/Project_3/hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\n\n# Load necessary library\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Load the data\nconjoint_data &lt;- read.csv(\"/Users/siddharthamysore/sid_site/blog/Project_3/conjoint_data.csv\")\n\n# Inspect data\nhead(conjoint_data)\n\n  resp task choice brand  ad price\n1    1    1      1     N Yes    28\n2    1    1      0     H Yes    16\n3    1    1      0     P Yes    16\n4    1    2      0     N Yes    32\n5    1    2      1     P Yes    16\n6    1    2      0     N Yes    24\n\n# One-hot encode brand and ad (Hulu and No are references)\nconjoint_data &lt;- conjoint_data %&gt;%\n  mutate(\n    brand_N = ifelse(brand == \"N\", 1, 0),\n    brand_P = ifelse(brand == \"P\", 1, 0),\n    ad_yes = ifelse(ad == \"Yes\", 1, 0)\n  )\n\n# Create a numeric respondent-task ID for grouping\nconjoint_data &lt;- conjoint_data %&gt;%\n  mutate(group = paste0(resp, \"_\", task))\n\n# Final design matrix X and outcome y\nX &lt;- conjoint_data %&gt;%\n  select(brand_N, brand_P, ad_yes, price) %&gt;%\n  as.matrix()\n\ny &lt;- conjoint_data$choice"
  },
  {
    "objectID": "blog/Project_3/hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "blog/Project_3/hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\n\nlog_likelihood &lt;- function(beta, X, y, group_ids) {\n  # Convert beta to column matrix\n  beta &lt;- matrix(beta, ncol = 1)\n  \n  # Compute utility\n  utilities &lt;- X %*% beta\n  exp_utilities &lt;- exp(utilities)\n  \n  # Data frame for group-level normalization\n  df &lt;- data.frame(\n    group = group_ids,\n    exp_utilities = exp_utilities,\n    y = y\n  )\n  \n  # Compute denominator for softmax per group\n  df$sum_exp &lt;- ave(df$exp_utilities, df$group, FUN = sum)\n  \n  # Compute probabilities\n  df$prob &lt;- df$exp_utilities / df$sum_exp\n  \n  # Log-likelihood only for chosen alternatives\n  log_lik &lt;- sum(log(df$prob[df$y == 1]))\n  \n  return(-log_lik)  # Negative for minimization\n}\n\n\n# Initial values for optimization\ninitial_beta &lt;- rep(0, 4)\n\n# Group identifiers (resp + task)\ngroup_ids &lt;- paste0(conjoint_data$resp, \"_\", conjoint_data$task)\n\n# Run MLE optimization\nmle &lt;- optim(\n  par = initial_beta,\n  fn = log_likelihood,\n  X = X,\n  y = y,\n  group_ids = group_ids,\n  hessian = TRUE,\n  method = \"BFGS\"\n)\n\n# Extract MLE estimates and compute standard errors\nbeta_hat &lt;- mle$par\nhessian &lt;- mle$hessian\nvcov &lt;- solve(hessian)  # Invert Hessian to get variance-covariance matrix\nse &lt;- sqrt(diag(vcov))  # Standard errors\n\n# Construct 95% confidence intervals\nci_lower &lt;- beta_hat - 1.96 * se\nci_upper &lt;- beta_hat + 1.96 * se\n\n# Compile results\nresults &lt;- data.frame(\n  Estimate = beta_hat,\n  Std_Error = se,\n  CI_Lower = ci_lower,\n  CI_Upper = ci_upper\n)\nrownames(results) &lt;- c(\"Brand_Netflix\", \"Brand_Prime\", \"Ad_Yes\", \"Price\")\n\n# Show the results\nknitr::kable(\n  results,\n  caption = \"Maximum Likelihood Estimates with 95% Confidence Intervals\",\n  digits = 3,\n  align = \"lccc\"\n)\n\n\nMaximum Likelihood Estimates with 95% Confidence Intervals\n\n\n\nEstimate\nStd_Error\nCI_Lower\nCI_Upper\n\n\n\n\nBrand_Netflix\n0.941\n0.111\n0.724\n1.159\n\n\nBrand_Prime\n0.502\n0.111\n0.284\n0.719\n\n\nAd_Yes\n-0.732\n0.088\n-0.904\n-0.560\n\n\nPrice\n-0.099\n0.006\n-0.112\n-0.087\n\n\n\n\n\n\n\n\n\n\n\n5. Estimation via Bayesian Methods\n\n\n\n\n\n\nset.seed(42)\n\n# Log-prior (matches hint: N(0,5) for binary, N(0,1) for price)\nlog_prior &lt;- function(beta) {\n  sum(dnorm(beta[1:3], mean = 0, sd = 5, log = TRUE)) +\n    dnorm(beta[4], mean = 0, sd = 1, log = TRUE)\n}\n\n# Log-posterior = log-likelihood + log-prior\nlog_posterior &lt;- function(beta, X, y, group_ids) {\n  -log_likelihood(beta, X, y, group_ids) + log_prior(beta)\n}\n\n# Metropolis-Hastings MCMC function\nmetropolis_sampler &lt;- function(start, n_iter, X, y, group_ids) {\n  chain &lt;- matrix(NA, nrow = n_iter, ncol = length(start))\n  chain[1, ] &lt;- start\n  \n  # Proposal std devs per dimension\n  proposal_sd &lt;- c(0.05, 0.05, 0.05, 0.005)\n  \n  for (i in 2:n_iter) {\n    current &lt;- chain[i - 1, ]\n    proposal &lt;- rnorm(4, mean = current, sd = proposal_sd)  # diagonal MVN\n    \n    log_alpha &lt;- log_posterior(proposal, X, y, group_ids) -\n                 log_posterior(current, X, y, group_ids)\n    \n    if (log(runif(1)) &lt; log_alpha) {\n      chain[i, ] &lt;- proposal  # accept\n    } else {\n      chain[i, ] &lt;- current  # reject\n    }\n  }\n  \n  colnames(chain) &lt;- c(\"Beta_Netflix\", \"Beta_Prime\", \"Beta_AdYes\", \"Beta_Price\")\n  return(chain)\n}\n\n# Run the MCMC sampler\nmcmc_chain &lt;- metropolis_sampler(\n  start = rep(0, 4),\n  n_iter = 11000,\n  X = X,\n  y = y,\n  group_ids = group_ids\n)\n\n# Drop burn-in: retain final 10,000 draws\nmcmc_post &lt;- mcmc_chain[1001:11000, ]\n\n\n# Extract Beta_Price draws\nbeta_price &lt;- mcmc_post[, \"Beta_Price\"]\n\n# Trace plot\nplot(beta_price, type = \"l\", col = \"blue\",\n     main = \"Trace Plot for Beta_Price\",\n     xlab = \"Iteration\", ylab = \"Value\")\n\n\n\n\n\n\n\n# Histogram of posterior distribution\nhist(beta_price, breaks = 50, col = \"lightblue\",\n     main = \"Posterior Distribution of Beta_Price\",\n     xlab = \"Beta_Price\", probability = TRUE)\n\n# Add density estimate\nlines(density(beta_price), col = \"darkblue\", lwd = 2)\n\n\n\n\n\n\n\n\n\n# Step 1: Posterior summary\nposterior_summary &lt;- apply(mcmc_post, 2, function(draws) {\n  c(\n    Mean = mean(draws),\n    SD = sd(draws),\n    CI_Lower = quantile(draws, 0.025),\n    CI_Upper = quantile(draws, 0.975)\n  )\n}) %&gt;% t() %&gt;% as.data.frame()\n\n# Step 2: MLE summary (from earlier)\nmle_summary &lt;- results[, c(\"Estimate\", \"Std_Error\", \"CI_Lower\", \"CI_Upper\")]\ncolnames(mle_summary) &lt;- c(\"Mean\", \"SD\", \"CI_Lower\", \"CI_Upper\")\n\n# Step 3: Combine into one comparison table\ncomparison &lt;- data.frame(\n  Parameter = rownames(posterior_summary),\n  MLE_Mean = mle_summary$Mean,\n  MLE_SD = mle_summary$SD,\n  MLE_CI_Lower = mle_summary$CI_Lower,\n  MLE_CI_Upper = mle_summary$CI_Upper,\n  Bayes_Mean = posterior_summary$Mean,\n  Bayes_SD = posterior_summary$SD,\n  Bayes_CI_Lower = posterior_summary$CI_Lower,\n  Bayes_CI_Upper = posterior_summary$CI_Upper\n)\n\n# Display comparison\nknitr::kable(\n  comparison,\n  caption = \"Comparison of MLE and Bayesian Estimates with 95% Intervals\",\n  digits = 3,\n  align = \"lccccccc\"\n)\n\n\nComparison of MLE and Bayesian Estimates with 95% Intervals\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMLE_Mean\nMLE_SD\nMLE_CI_Lower\nMLE_CI_Upper\nBayes_Mean\nBayes_SD\nBayes_CI_Lower\nBayes_CI_Upper\n\n\n\n\nBeta_Netflix\n0.941\n0.111\n0.724\n1.159\n0.947\n0.114\n0.731\n1.166\n\n\nBeta_Prime\n0.502\n0.111\n0.284\n0.719\n0.497\n0.116\n0.276\n0.732\n\n\nBeta_AdYes\n-0.732\n0.088\n-0.904\n-0.560\n-0.737\n0.088\n-0.902\n-0.564\n\n\nBeta_Price\n-0.099\n0.006\n-0.112\n-0.087\n-0.100\n0.006\n-0.112\n-0.088\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6. Discussion\n\n\n\n\n\n\nSuppose you did not simulate the data. What do you observe about the parameter estimates?\nIf the data were not simulated, the parameter estimates would reflect actual consumer preferences derived from observed choice behavior. In this case, we would interpret each coefficient as an empirical estimate of how much that feature contributes to the utility of a product. The magnitude and direction of the coefficients would tell us which attributes are most valued by consumers.\nAdditionally, the standard errors or credible intervals would indicate the precision of these estimates, influenced by the sample size, the design of the experiment, and how much variation exists in the attribute levels.\n\n\nWhat does \\(\\beta_\\text{Netflix} &gt; \\beta_\\text{Prime}\\) mean?\nThis means that, all else equal (same price and ad status), consumers derive more utility from Netflix than from Amazon Prime. In other words, Netflix is generally preferred over Prime by the average consumer in the sample. This could reflect brand perception, content quality, or user experience advantages.\n\n\nDoes it make sense that \\(\\beta_\\text{price}\\) is negative?\nYes, this is both expected and logical. A negative coefficient on price indicates that higher prices reduce the utility of a streaming option, which in turn makes it less likely to be chosen. This is consistent with standard economic intuition: consumers prefer lower prices, and demand typically decreases as price increases. The more negative the coefficient, the more price-sensitive the consumers are.\n\n\nSimulating and Estimating a Multi-Level (Hierarchical) Model\nTo simulate data from — and estimate parameters of — a multi-level (random-parameter or hierarchical) model, the key change is to allow individual-level heterogeneity in preferences.\n\n🔄 Simulation Changes\nIn the current setup, every respondent shares the same true β vector (part-worths). In a hierarchical model, each respondent gets their own β drawn from a population distribution:\n\nLet \\(\\beta_i \\sim \\mathcal{N}(\\mu, \\Sigma)\\) for respondent i\nThen, utility becomes \\(U_{ij} = x_{j}'\\beta_i + \\varepsilon_{ij}\\)\n\nTo simulate this: 1. First draw a unique \\(\\beta_i\\) for each individual from the population distribution. 2. Then simulate choices using those respondent-specific betas.\n\n\n📈 Estimation Changes\nIn estimation, a hierarchical Bayes model would: - Place priors on both the individual-level coefficients (\\(\\beta_i\\)) and the hyperparameters (\\(\\mu\\), \\(\\Sigma\\)) - Use MCMC to alternate between drawing: - \\(\\beta_i\\) for each respondent - The population-level parameters (\\(\\mu\\), \\(\\Sigma\\))\nThis allows the model to borrow strength across individuals while capturing preference heterogeneity.\nIn practice, hierarchical MNL models are used in real-world conjoint studies because they: - Improve prediction accuracy - Reflect the true diversity in consumer preferences - Enable targeting and segmentation based on individual-level part-worths"
  },
  {
    "objectID": "blog/Project_3/hw3_questions.html#estimation-via-bayesian-methods",
    "href": "blog/Project_3/hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\n\nset.seed(42)\n\n# Log-prior (matches hint: N(0,5) for binary, N(0,1) for price)\nlog_prior &lt;- function(beta) {\n  sum(dnorm(beta[1:3], mean = 0, sd = 5, log = TRUE)) +\n    dnorm(beta[4], mean = 0, sd = 1, log = TRUE)\n}\n\n# Log-posterior = log-likelihood + log-prior\nlog_posterior &lt;- function(beta, X, y, group_ids) {\n  -log_likelihood(beta, X, y, group_ids) + log_prior(beta)\n}\n\n# Metropolis-Hastings MCMC function\nmetropolis_sampler &lt;- function(start, n_iter, X, y, group_ids) {\n  chain &lt;- matrix(NA, nrow = n_iter, ncol = length(start))\n  chain[1, ] &lt;- start\n  \n  # Proposal std devs per dimension\n  proposal_sd &lt;- c(0.05, 0.05, 0.05, 0.005)\n  \n  for (i in 2:n_iter) {\n    current &lt;- chain[i - 1, ]\n    proposal &lt;- rnorm(4, mean = current, sd = proposal_sd)  # diagonal MVN\n    \n    log_alpha &lt;- log_posterior(proposal, X, y, group_ids) -\n                 log_posterior(current, X, y, group_ids)\n    \n    if (log(runif(1)) &lt; log_alpha) {\n      chain[i, ] &lt;- proposal  # accept\n    } else {\n      chain[i, ] &lt;- current  # reject\n    }\n  }\n  \n  colnames(chain) &lt;- c(\"Beta_Netflix\", \"Beta_Prime\", \"Beta_AdYes\", \"Beta_Price\")\n  return(chain)\n}\n\n# Run the MCMC sampler\nmcmc_chain &lt;- metropolis_sampler(\n  start = rep(0, 4),\n  n_iter = 11000,\n  X = X,\n  y = y,\n  group_ids = group_ids\n)\n\n# Drop burn-in: retain final 10,000 draws\nmcmc_post &lt;- mcmc_chain[1001:11000, ]\n\n\n# Extract Beta_Price draws\nbeta_price &lt;- mcmc_post[, \"Beta_Price\"]\n\n# Trace plot\nplot(beta_price, type = \"l\", col = \"blue\",\n     main = \"Trace Plot for Beta_Price\",\n     xlab = \"Iteration\", ylab = \"Value\")\n\n\n\n\n\n\n\n# Histogram of posterior distribution\nhist(beta_price, breaks = 50, col = \"lightblue\",\n     main = \"Posterior Distribution of Beta_Price\",\n     xlab = \"Beta_Price\", probability = TRUE)\n\n# Add density estimate\nlines(density(beta_price), col = \"darkblue\", lwd = 2)\n\n\n\n\n\n\n\n\n\n# Step 1: Posterior summary\nposterior_summary &lt;- apply(mcmc_post, 2, function(draws) {\n  c(\n    Mean = mean(draws),\n    SD = sd(draws),\n    CI_Lower = quantile(draws, 0.025),\n    CI_Upper = quantile(draws, 0.975)\n  )\n}) %&gt;% t() %&gt;% as.data.frame()\n\n# Step 2: MLE summary (from earlier)\nmle_summary &lt;- results[, c(\"Estimate\", \"Std_Error\", \"CI_Lower\", \"CI_Upper\")]\ncolnames(mle_summary) &lt;- c(\"Mean\", \"SD\", \"CI_Lower\", \"CI_Upper\")\n\n# Step 3: Combine into one comparison table\ncomparison &lt;- data.frame(\n  Parameter = rownames(posterior_summary),\n  MLE_Mean = mle_summary$Mean,\n  MLE_SD = mle_summary$SD,\n  MLE_CI_Lower = mle_summary$CI_Lower,\n  MLE_CI_Upper = mle_summary$CI_Upper,\n  Bayes_Mean = posterior_summary$Mean,\n  Bayes_SD = posterior_summary$SD,\n  Bayes_CI_Lower = posterior_summary$CI_Lower,\n  Bayes_CI_Upper = posterior_summary$CI_Upper\n)\n\n# Display comparison\ncomparison\n\n     Parameter    MLE_Mean      MLE_SD MLE_CI_Lower MLE_CI_Upper  Bayes_Mean\n1 Beta_Netflix  0.94120473 0.111039639    0.7235670   1.15884242  0.94747920\n2   Beta_Prime  0.50161701 0.111100000    0.2838610   0.71937301  0.49745186\n3   Beta_AdYes -0.73200143 0.087809687   -0.9041084  -0.55989445 -0.73693354\n4   Beta_Price -0.09948157 0.006333649   -0.1118955  -0.08706762 -0.09997048\n     Bayes_SD Bayes_CI_Lower Bayes_CI_Upper\n1 0.113781045      0.7307577     1.16590851\n2 0.116295583      0.2758532     0.73166426\n3 0.088404692     -0.9015843    -0.56381101\n4 0.006256914     -0.1123232    -0.08799356"
  },
  {
    "objectID": "blog/Project_3/hw3_questions.html#discussion",
    "href": "blog/Project_3/hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\n\nSuppose you did not simulate the data. What do you observe about the parameter estimates?\nIf the data were not simulated, the parameter estimates would reflect actual consumer preferences derived from observed choice behavior. In this case, we would interpret each coefficient as an empirical estimate of how much that feature contributes to the utility of a product. The magnitude and direction of the coefficients would tell us which attributes are most valued by consumers.\nAdditionally, the standard errors or credible intervals would indicate the precision of these estimates, influenced by the sample size, the design of the experiment, and how much variation exists in the attribute levels.\n\n\nWhat does \\(\\beta_\\text{Netflix} &gt; \\beta_\\text{Prime}\\) mean?\nThis means that, all else equal (same price and ad status), consumers derive more utility from Netflix than from Amazon Prime. In other words, Netflix is generally preferred over Prime by the average consumer in the sample. This could reflect brand perception, content quality, or user experience advantages.\n\n\nDoes it make sense that \\(\\beta_\\text{price}\\) is negative?\nYes, this is both expected and logical. A negative coefficient on price indicates that higher prices reduce the utility of a streaming option, which in turn makes it less likely to be chosen. This is consistent with standard economic intuition: consumers prefer lower prices, and demand typically decreases as price increases. The more negative the coefficient, the more price-sensitive the consumers are.\n\n\nSimulating and Estimating a Multi-Level (Hierarchical) Model\nTo simulate data from — and estimate parameters of — a multi-level (random-parameter or hierarchical) model, the key change is to allow individual-level heterogeneity in preferences.\n\n🔄 Simulation Changes\nIn the current setup, every respondent shares the same true β vector (part-worths). In a hierarchical model, each respondent gets their own β drawn from a population distribution:\n\nLet \\(\\beta_i \\sim \\mathcal{N}(\\mu, \\Sigma)\\) for respondent i\nThen, utility becomes \\(U_{ij} = x_{j}'\\beta_i + \\varepsilon_{ij}\\)\n\nTo simulate this: 1. First draw a unique \\(\\beta_i\\) for each individual from the population distribution. 2. Then simulate choices using those respondent-specific betas.\n\n\n📈 Estimation Changes\nIn estimation, a hierarchical Bayes model would: - Place priors on both the individual-level coefficients (\\(\\beta_i\\)) and the hyperparameters (\\(\\mu\\), \\(\\Sigma\\)) - Use MCMC to alternate between drawing: - \\(\\beta_i\\) for each respondent - The population-level parameters (\\(\\mu\\), \\(\\Sigma\\))\nThis allows the model to borrow strength across individuals while capturing preference heterogeneity.\nIn practice, hierarchical MNL models are used in real-world conjoint studies because they: - Improve prediction accuracy - Reflect the true diversity in consumer preferences - Enable targeting and segmentation based on individual-level part-worths"
  },
  {
    "objectID": "blog/Project_3/hw3_questions.html#discussion-1",
    "href": "blog/Project_3/hw3_questions.html#discussion-1",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\n\nSuppose you did not simulate the data. What do you observe about the parameter estimates?\nIf the data were not simulated, the parameter estimates would reflect actual consumer preferences derived from observed choice behavior. In this case, we would interpret each coefficient as an empirical estimate of how much that feature contributes to the utility of a product. The magnitude and direction of the coefficients would tell us which attributes are most valued by consumers.\nAdditionally, the standard errors or credible intervals would indicate the precision of these estimates, influenced by the sample size, the design of the experiment, and how much variation exists in the attribute levels.\n\n\nWhat does \\(\\beta_\\text{Netflix} &gt; \\beta_\\text{Prime}\\) mean?\nThis means that, all else equal (same price and ad status), consumers derive more utility from Netflix than from Amazon Prime. In other words, Netflix is generally preferred over Prime by the average consumer in the sample. This could reflect brand perception, content quality, or user experience advantages.\n\n\nDoes it make sense that \\(\\beta_\\text{price}\\) is negative?\nYes, this is both expected and logical. A negative coefficient on price indicates that higher prices reduce the utility of a streaming option, which in turn makes it less likely to be chosen. This is consistent with standard economic intuition: consumers prefer lower prices, and demand typically decreases as price increases. The more negative the coefficient, the more price-sensitive the consumers are.\ntodo: At a high level, discuss what change you would need to make in order to simulate data from — and estimate the parameters of — a multi-level (aka random-parameter or hierarchical) model. This is the model we use to analyze “real world” conjoint data.\n\n\nSimulating and Estimating a Multi-Level (Hierarchical) Model\nTo simulate data from — and estimate parameters of — a multi-level (random-parameter or hierarchical) model, the key change is to allow individual-level heterogeneity in preferences.\n\n🔄 Simulation Changes\nIn the current setup, every respondent shares the same true β vector (part-worths). In a hierarchical model, each respondent gets their own β drawn from a pop"
  },
  {
    "objectID": "blog/Project_4/hw4_questions.html",
    "href": "blog/Project_4/hw4_questions.html",
    "title": "Homework 4",
    "section": "",
    "text": "todo: do two analyses. Do one of either 1a or 1b, AND one of either 2a or 2b."
  },
  {
    "objectID": "blog/Project_4/hw4_questions.html#a.-k-means",
    "href": "blog/Project_4/hw4_questions.html#a.-k-means",
    "title": "Homework 4",
    "section": "1a. K-Means",
    "text": "1a. K-Means\n\n# Load data\npenguins &lt;- read.csv(\"/Users/siddharthamysore/sid_site/blog/Project_4/palmer_penguins.csv\")\npenguins &lt;- penguins[!is.na(penguins$bill_length_mm) & !is.na(penguins$flipper_length_mm),\n                     c(\"bill_length_mm\", \"flipper_length_mm\")]\nX &lt;- as.matrix(penguins)\nset.seed(123)\n\n\ninitialize_centroids &lt;- function(X, k) {\n  idx &lt;- sample(1:nrow(X), k)\n  X[idx, ]\n}\n\nassign_clusters &lt;- function(X, centroids) {\n  apply(X, 1, function(x) {\n    which.min(colSums((t(centroids) - x)^2))\n  })\n}\n\nupdate_centroids &lt;- function(X, clusters, k) {\n  centroids &lt;- matrix(NA, nrow = k, ncol = ncol(X))\n  for (i in 1:k) {\n    centroids[i, ] &lt;- colMeans(X[clusters == i, , drop = FALSE])\n  }\n  centroids\n}\n\nkmeans_custom_with_tracking &lt;- function(X, k, max_iters = 10, tol = 1e-4) {\n  centroids &lt;- initialize_centroids(X, k)\n  steps &lt;- list()\n  \n  for (i in 1:max_iters) {\n    clusters &lt;- assign_clusters(X, centroids)\n    steps[[i]] &lt;- list(centroids = centroids, clusters = clusters)\n    new_centroids &lt;- update_centroids(X, clusters, k)\n    if (sum((centroids - new_centroids)^2) &lt; tol) break\n    centroids &lt;- new_centroids\n  }\n  \n  list(centroids = centroids, clusters = clusters, steps = steps)\n}\n\n\n# Run your custom K-means algorithm and store the results\nk &lt;- 3\nresult &lt;- kmeans_custom_with_tracking(X, k)\nsteps &lt;- result$steps\n\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Safely create plot list\nplot_list &lt;- lapply(seq_along(steps), function(i) {\n  s &lt;- steps[[i]]\n  if (is.null(s$centroids) || is.null(s$clusters)) return(NULL)\n  \n  cent &lt;- as.data.frame(s$centroids)\n  colnames(cent) &lt;- c(\"bill_length_mm\", \"flipper_length_mm\")\n  \n  df &lt;- as.data.frame(X)\n  df$cluster &lt;- factor(s$clusters)\n\n  ggplot(df, aes(x = bill_length_mm, y = flipper_length_mm, color = cluster)) +\n    geom_point(size = 2) +\n    geom_point(data = cent, aes(x = bill_length_mm, y = flipper_length_mm),\n               color = \"black\", shape = 4, size = 4, stroke = 2) +\n    labs(title = paste(\"Iteration\", i), color = \"Cluster\") +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(size = 14, face = \"bold\"),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 8),\n      legend.position = \"none\"\n    )\n})\n\n# Remove any NULLs before plotting\nplot_list_clean &lt;- plot_list[!sapply(plot_list, is.null)]\n\n# Combine plots into 2 rows\nwrap_plots(plot_list_clean, nrow = 2)\n\n\n\n\n\n\n\n\n\nkmeans_builtin &lt;- kmeans(X, centers = 3, nstart = 25)\ndf_builtin &lt;- as.data.frame(X)\ndf_builtin$cluster &lt;- factor(kmeans_builtin$cluster)\n\nggplot(df_builtin, aes(x = bill_length_mm, y = flipper_length_mm, color = cluster)) +\n  geom_point(size = 2) +\n  geom_point(data = as.data.frame(kmeans_builtin$centers),\n             aes(x = bill_length_mm, y = flipper_length_mm),\n             shape = 4, color = \"black\", size = 4, stroke = 2) +\n  labs(title = \"Built-in KMeans (K = 3)\", color = \"Cluster\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(cluster)     # silhouette()\nlibrary(patchwork)   # side-by-side plots\n\nwcss &lt;- numeric(6)        # for K = 2 to 7\nsil_scores &lt;- numeric(6)  # same length\n\nfor (k in 2:7) {\n  km &lt;- kmeans(X, centers = k, nstart = 25)\n  wcss[k - 1] &lt;- km$tot.withinss\n  \n  sil &lt;- silhouette(km$cluster, dist(X))\n  sil_scores[k - 1] &lt;- mean(sil[, 3])\n}\n\n\n# Elbow Plot (WCSS)\nelbow_plot &lt;- ggplot(data.frame(K = 2:7, WCSS = wcss), aes(x = K, y = WCSS)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_point(size = 3) +\n  labs(title = \"Elbow Method\", x = \"Number of Clusters (K)\", y = \"WCSS\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n# Silhouette Plot\nsil_plot &lt;- ggplot(data.frame(K = 2:7, Silhouette = sil_scores), aes(x = K, y = Silhouette)) +\n  geom_line(color = \"darkgreen\", size = 1) +\n  geom_point(size = 3) +\n  labs(title = \"Silhouette Scores\", x = \"Number of Clusters (K)\", y = \"Average Silhouette\") +\n  theme_minimal()\n\n# Show side by side\nelbow_plot + sil_plot\n\n\n\n\n\n\n\n\nIf you want a challenge, add your plots as an animated gif on your website so that the result looks something like this."
  },
  {
    "objectID": "blog/Project_4/hw4_questions.html#b.-latent-class-mnl",
    "href": "blog/Project_4/hw4_questions.html#b.-latent-class-mnl",
    "title": "Homework 4",
    "section": "1b. Latent-Class MNL",
    "text": "1b. Latent-Class MNL\ntodo: Use the Yogurt dataset to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989); you may want to read or reference page 2 of the pdf, which is described in the class slides, session 4, slides 56-57.\nThe data provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices in price-per-ounce (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc. You may want to reshape the data from its current “wide” format into a “long” format.\ntodo: Fit the standard MNL model on these data. Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes.\ntodo: How many classes are suggested by the \\(BIC = -2*\\ell_n  + k*log(n)\\)? (where \\(\\ell_n\\) is the log-likelihood, \\(n\\) is the sample size, and \\(k\\) is the number of parameters.) The Bayesian-Schwarz Information Criterion link is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate – akin to the adjusted R-squared for the linear regression model. Note, that a lower BIC indicates a better model fit, accounting for the number of parameters in the model.\ntodo: compare the parameter estimates between (1) the aggregate MNL, and (2) the latent-class MNL with the number of classes suggested by the BIC."
  },
  {
    "objectID": "blog/Project_4/hw4_questions.html#a.-k-nearest-neighbors",
    "href": "blog/Project_4/hw4_questions.html#a.-k-nearest-neighbors",
    "title": "Homework 4",
    "section": "2a. K Nearest Neighbors",
    "text": "2a. K Nearest Neighbors\ntodo: use the following code (or the python equivalent) to generate a synthetic dataset for the k-nearest neighbors algorithm. The code generates a dataset with two features, x1 and x2, and a binary outcome variable y that is determined by whether x2 is above or below a wiggly boundary defined by a sin function.\n\n# Load necessary libraries\nlibrary(ggplot2)\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Number of points\nn &lt;- 100\n\n# Generate features\nx1 &lt;- runif(n, -3, 3)\nx2 &lt;- runif(n, -3, 3)\n\n# Define the wiggly boundary\nboundary &lt;- sin(4 * x1) + x1\n\n# Binary outcome: 1 if x2 is above the boundary, else 0\ny &lt;- ifelse(x2 &gt; boundary, 1, 0)\n\n# Combine into a data frame\ndat &lt;- data.frame(x1 = x1, x2 = x2, y = as.factor(y))\n\n# Create a boundary curve for plotting\nboundary_df &lt;- data.frame(x1 = seq(-3, 3, length.out = 300))\nboundary_df$x2 &lt;- sin(4 * boundary_df$x1) + boundary_df$x1\n\n# Plot the synthetic dataset\nggplot(dat, aes(x = x1, y = x2, color = y)) +\n  geom_point(size = 2.5) +\n  geom_line(data = boundary_df, aes(x = x1, y = x2), \n            color = \"black\", linetype = \"dashed\", linewidth = 1) +\n  scale_color_manual(values = c(\"blue\", \"red\"), labels = c(\"Class 0\", \"Class 1\")) +\n  labs(\n    title = \"Synthetic KNN Dataset with Sinusoidal Boundary\",\n    x = \"x1\", y = \"x2\", color = \"Class\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\ntodo: plot the data where the horizontal axis is x1, the vertical axis is x2, and the points are colored by the value of y. You may optionally draw the wiggly boundary.\n\n# Load required library\nlibrary(ggplot2)\n\n# Assuming dat and boundary_df are already created\n# If not, recreate them here (just in case)\nset.seed(42)\nn &lt;- 100\nx1 &lt;- runif(n, -3, 3)\nx2 &lt;- runif(n, -3, 3)\nboundary &lt;- sin(4 * x1) + x1\ny &lt;- ifelse(x2 &gt; boundary, 1, 0)\ndat &lt;- data.frame(x1 = x1, x2 = x2, y = as.factor(y))\n\nboundary_df &lt;- data.frame(x1 = seq(-3, 3, length.out = 300))\nboundary_df$x2 &lt;- sin(4 * boundary_df$x1) + boundary_df$x1\n\n# Plot the dataset\nggplot(dat, aes(x = x1, y = x2, color = y)) +\n  geom_point(size = 2.5, alpha = 0.85) +\n  geom_line(data = boundary_df, aes(x = x1, y = x2),\n            color = \"black\", linetype = \"dashed\", linewidth = 1) +\n  scale_color_manual(values = c(\"blue\", \"red\"), labels = c(\"Class 0\", \"Class 1\")) +\n  labs(\n    title = \"Synthetic Classification Data\",\n    subtitle = \"With Optional Sinusoidal Decision Boundary\",\n    x = \"x1\", y = \"x2\", color = \"Class (y)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\ntodo: generate a test dataset with 100 points, using the same code as above but with a different seed.\n\n# Generate a test dataset with a different seed\nset.seed(2025)\n\nn_test &lt;- 100\nx1_test &lt;- runif(n_test, -3, 3)\nx2_test &lt;- runif(n_test, -3, 3)\n\n# Define the same sinusoidal boundary\nboundary_test &lt;- sin(4 * x1_test) + x1_test\ny_test &lt;- ifelse(x2_test &gt; boundary_test, 1, 0)\n\n# Create test data frame\ntest_data &lt;- data.frame(\n  x1 = x1_test,\n  x2 = x2_test,\n  y = as.factor(y_test)\n)\n\n# Optional: create boundary for plotting\nboundary_df_test &lt;- data.frame(\n  x1 = seq(-3, 3, length.out = 300)\n)\nboundary_df_test$x2 &lt;- sin(4 * boundary_df_test$x1) + boundary_df_test$x1\n\n# Plot the test set\nggplot(test_data, aes(x = x1, y = x2, color = y)) +\n  geom_point(size = 2.5, alpha = 0.85) +\n  geom_line(data = boundary_df_test, aes(x = x1, y = x2),\n            color = \"black\", linetype = \"dashed\", linewidth = 1) +\n  scale_color_manual(values = c(\"blue\", \"red\"), labels = c(\"Class 0\", \"Class 1\")) +\n  labs(\n    title = \"Test Dataset with Sinusoidal Boundary\",\n    x = \"x1\", y = \"x2\", color = \"Class (y)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\ntodo: implement KNN by hand. Check you work with a built-in function – eg, class::knn() or caret::train(method=\"knn\") in R, or scikit-learn’s KNeighborsClassifier in Python.\n\nknn_manual &lt;- function(train_x, train_y, test_x, k) {\n  pred &lt;- character(nrow(test_x))  # prediction vector\n  \n  for (i in 1:nrow(test_x)) {\n    # Compute Euclidean distances\n    dists &lt;- sqrt(rowSums((train_x - matrix(rep(test_x[i, ], nrow(train_x)), ncol = 2, byrow = TRUE))^2))\n    \n    # Get indices of k nearest neighbors (k is dynamic)\n    neighbors &lt;- order(dists)[1:k]\n    \n    # Majority vote\n    neighbor_labels &lt;- train_y[neighbors]\n    pred[i] &lt;- names(sort(table(neighbor_labels), decreasing = TRUE))[1]\n  }\n  \n  return(factor(pred, levels = levels(train_y)))\n}"
  },
  {
    "objectID": "blog/Project_4/hw4_questions.html#b.-key-drivers-analysis",
    "href": "blog/Project_4/hw4_questions.html#b.-key-drivers-analysis",
    "title": "Homework 4",
    "section": "2b. Key Drivers Analysis",
    "text": "2b. Key Drivers Analysis\ntodo: replicate the table on slide 75 of the session 5 slides. Specifically, using the dataset provided in the file data_for_drivers_analysis.csv, calculate: pearson correlations, standardized regression coefficients, “usefulness”, Shapley values for a linear regression, Johnson’s relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python; you do not need to perform these calculations “by hand.”\nIf you want a challenge, add additional measures to the table such as the importance scores from XGBoost, from a Neural Network, or from any additional method that measures the importance of variables."
  },
  {
    "objectID": "blog/Project_4/hw4_questions.html#apply-manual-knn-on-test-set-k-5",
    "href": "blog/Project_4/hw4_questions.html#apply-manual-knn-on-test-set-k-5",
    "title": "Homework 4",
    "section": "🔍 Apply Manual KNN on Test Set (k = 5)",
    "text": "🔍 Apply Manual KNN on Test Set (k = 5)\n\nlibrary(class)\n\n# Ensure factor levels are consistent\ntrain_y &lt;- factor(dat$y)\ntest_y &lt;- factor(test_data$y, levels = levels(train_y))\n\n# Convert to matrices for manual KNN\ntrain_x &lt;- as.matrix(dat[, c(\"x1\", \"x2\")])\ntest_x &lt;- as.matrix(test_data[, c(\"x1\", \"x2\")])\n\n# Predict using manual KNN\npred_manual &lt;- knn_manual(train_x, train_y, test_x, k = 5)\nmanual_accuracy &lt;- mean(pred_manual == test_y)\n\n# Predict using built-in KNN\npred_builtin &lt;- knn(train = train_x, test = test_x, cl = train_y, k = 5)\nbuiltin_accuracy &lt;- mean(pred_builtin == test_y)\n\n# Show both accuracies\nmanual_accuracy\n\n[1] 0.88\n\nbuiltin_accuracy\n\n[1] 0.88\n\n\ntodo: run your function for k=1,…,k=30, each time noting the percentage of correctly-classified points from the test dataset. Plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points. What is the optimal value of k as suggested by your plot?\n\n# Initialize accuracy storage vector\naccuracy_vec &lt;- numeric(30)\n\n# Run manual KNN for k = 1 to 30\nfor (k in 1:30) {\n  pred_k &lt;- knn_manual(train_x, train_y, test_x, k)\n  accuracy_vec[k] &lt;- mean(pred_k == test_y)\n}\n\n\n# Create data frame for plotting\nacc_df &lt;- data.frame(k = 1:30, accuracy = 100 * accuracy_vec)\n\nlibrary(ggplot2)\n\nggplot(acc_df, aes(x = k, y = accuracy)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_point(size = 2) +\n  geom_vline(xintercept = which.max(accuracy_vec), linetype = \"dashed\", color = \"red\") +\n  annotate(\"text\", x = which.max(accuracy_vec), y = max(100 * accuracy_vec),\n           label = paste(\"Best k =\", which.max(accuracy_vec)),\n           vjust = -1, color = \"red\", size = 4) +\n  labs(\n    title = \"Test Accuracy vs. Number of Nearest Neighbors (k)\",\n    x = \"k (Number of Neighbors)\",\n    y = \"Test Accuracy (%)\"\n  ) +\n  theme_minimal()"
  }
]