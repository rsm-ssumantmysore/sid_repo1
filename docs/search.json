[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Siddhartha Sumant Mysore",
    "section": "",
    "text": "SiddharthAAA Mysore"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nYour Name\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nSiddhartha Sumant Mysore\n\n\nMay 7, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/Project_1/index.html",
    "href": "blog/Project_1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data.\n\n\n\nI analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt;\n    ggplot(aes(x = wt, y = mpg)) +\n    geom_point()"
  },
  {
    "objectID": "blog/Project_1/index.html#section-1-data",
    "href": "blog/Project_1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data."
  },
  {
    "objectID": "blog/Project_1/index.html#section-2-analysis",
    "href": "blog/Project_1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt;\n    ggplot(aes(x = wt, y = mpg)) +\n    geom_point()"
  },
  {
    "objectID": "blog/AB_Testing/index1.html",
    "href": "blog/AB_Testing/index1.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/AB_Testing/index1.html#introduction",
    "href": "blog/AB_Testing/index1.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/AB_Testing/index1.html#data",
    "href": "blog/AB_Testing/index1.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\n\n\n\n\n\nDescription\n\n\n\n\n\n\nlibrary(haven)\n\n# Load the data from the current working directory\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\nlist.files()\n\n[1] \"index1_files\"         \"index1.qmd\"           \"index1.rmarkdown\"    \n[4] \"karlan_list_2007.dta\"\n\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\n\n\n\n\n#_todo: Read the data into R/Python and describe the data_\n## Load libraries\nlibrary(haven)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Read the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# View structure of the dataset\nstr(data)\n\ntibble [50,083 × 51] (S3: tbl_df/tbl/data.frame)\n $ treatment         : num [1:50083] 0 0 1 1 1 0 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Treatment\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ control           : num [1:50083] 1 1 0 0 0 1 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Control\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ratio             : dbl+lbl [1:50083] 0, 0, 1, 1, 1, 0, 1, 2, 2, 1, 1, 2, 0, 2, 0, 1, 3, 3...\n   ..@ label       : chr \"Match ratio\"\n   ..@ format.stata: chr \"%9.0g\"\n   ..@ labels      : Named num 0\n   .. ..- attr(*, \"names\")= chr \"Control\"\n $ ratio2            : num [1:50083] 0 0 0 0 0 0 0 1 1 0 ...\n  ..- attr(*, \"label\")= chr \"2:1 match ratio\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ratio3            : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"3:1 match ratio\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ size              : dbl+lbl [1:50083] 0, 0, 3, 4, 2, 0, 1, 3, 4, 1, 4, 2, 0, 1, 0, 4, 1, 4...\n   ..@ label       : chr \"Match threshold\"\n   ..@ format.stata: chr \"%9.0g\"\n   ..@ labels      : Named num [1:5] 0 1 2 3 4\n   .. ..- attr(*, \"names\")= chr [1:5] \"Control\" \"$25,000\" \"$50,000\" \"$100,000\" ...\n $ size25            : num [1:50083] 0 0 0 0 0 0 1 0 0 1 ...\n  ..- attr(*, \"label\")= chr \"$25,000 match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ size50            : num [1:50083] 0 0 0 0 1 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"$50,000 match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ size100           : num [1:50083] 0 0 1 0 0 0 0 1 0 0 ...\n  ..- attr(*, \"label\")= chr \"$100,000 match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ sizeno            : num [1:50083] 0 0 0 1 0 0 0 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"Unstated match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ask               : dbl+lbl [1:50083] 0, 0, 1, 1, 1, 0, 3, 3, 2, 2, 1, 3, 0, 2, 0, 1, 2, 3...\n   ..@ label       : chr \"Suggested donation amount\"\n   ..@ format.stata: chr \"%9.0g\"\n   ..@ labels      : Named num [1:4] 0 1 2 3\n   .. ..- attr(*, \"names\")= chr [1:4] \"Control\" \"1x\" \"1.25x\" \"1.50x\"\n $ askd1             : num [1:50083] 0 0 1 1 1 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Suggested donation was highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ askd2             : num [1:50083] 0 0 0 0 0 0 0 0 1 1 ...\n  ..- attr(*, \"label\")= chr \"Suggested donation was 1.25 x highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ askd3             : num [1:50083] 0 0 0 0 0 0 1 1 0 0 ...\n  ..- attr(*, \"label\")= chr \"Suggested donation was 1.50 x highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ask1              : num [1:50083] 55 25 55 55 35 95 125 75 250 150 ...\n  ..- attr(*, \"label\")= chr \"Highest previous contribution (for suggestion)\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ ask2              : num [1:50083] 70 35 70 70 45 120 160 95 315 190 ...\n  ..- attr(*, \"label\")= chr \"1.25 x highest previous contribution (for suggestion)\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ ask3              : num [1:50083] 85 50 85 85 55 145 190 120 375 225 ...\n  ..- attr(*, \"label\")= chr \"1.50 x highest previous contribution (for suggestion)\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ amount            : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Dollars given\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2f\"\n $ gave              : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Gave anything\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ amountchange      : num [1:50083] -45 -25 -50 -25 -15 -45 -50 -65 -100 -125 ...\n  ..- attr(*, \"label\")= chr \"Change in amount given\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2fc\"\n $ hpa               : num [1:50083] 45 25 50 50 25 90 100 65 200 125 ...\n  ..- attr(*, \"label\")= chr \"Highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2fc\"\n $ ltmedmra          : num [1:50083] 0 1 0 1 1 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Small prior donor: last gift was less than median $35\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ freq              : num [1:50083] 2 2 3 15 42 20 12 13 28 4 ...\n  ..- attr(*, \"label\")= chr \"Number of prior donations\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ years             : num [1:50083] 4 3 2 8 95 10 8 16 19 7 ...\n  ..- attr(*, \"label\")= chr \"Number of years since initial donation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ year5             : num [1:50083] 0 0 0 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"At least 5 years since initial donation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ mrm2              : num [1:50083] 31 5 6 1 24 3 4 4 6 35 ...\n  ..- attr(*, \"label\")= chr \"Number of months since last donation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ dormant           : num [1:50083] 1 0 0 0 1 0 0 0 0 1 ...\n  ..- attr(*, \"label\")= chr \"Already donated in 2005\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ female            : num [1:50083] 0 0 0 0 1 0 1 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Female\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ couple            : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Couple\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ state50one        : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"State tag: 1 for one observation of each of 50 states; 0 otherwise\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ nonlit            : num [1:50083] 5 0 3 1 1 0 0 4 1 4 ...\n  ..- attr(*, \"label\")= chr \"Nonlitigation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ cases             : num [1:50083] 4 2 1 2 1 0 1 3 1 3 ...\n  ..- attr(*, \"label\")= chr \"Court cases from state in 2004-5 in which organization was involved\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ statecnt          : num [1:50083] 4.5 2.98 9.61 3.28 2.3 ...\n  ..- attr(*, \"label\")= chr \"Percent of sample from state\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2f\"\n $ stateresponse     : num [1:50083] 0.0199 0.0261 0.023 0.0207 0.0156 ...\n  ..- attr(*, \"label\")= chr \"Proportion of sample from the state who gave\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ stateresponset    : num [1:50083] 0.0195 0.0278 0.0222 0.0247 0.017 ...\n  ..- attr(*, \"label\")= chr \"Proportion of treated sample from the state who gave\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ stateresponsec    : num [1:50083] 0.0208 0.0225 0.0247 0.0127 0.0129 ...\n  ..- attr(*, \"label\")= chr \"Proportion of control sample from the state who gave\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ stateresponsetminc: num [1:50083] -0.0013 0.00534 -0.00258 0.01202 0.00408 ...\n  ..- attr(*, \"label\")= chr \"stateresponset - stateresponsec\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ perbush           : num [1:50083] 0.49 0.465 0.408 0.465 0.525 ...\n  ..- attr(*, \"label\")= chr \"State vote share for Bush\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ close25           : num [1:50083] 1 0 0 0 0 1 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"State vote share for Bush between 47.5% and 52.5%\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ red0              : num [1:50083] 0 0 0 0 1 1 1 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"Red state\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ blue0             : num [1:50083] 1 1 1 1 0 0 0 1 0 1 ...\n  ..- attr(*, \"label\")= chr \"Blue state\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ redcty            : num [1:50083] 0 1 0 1 0 1 1 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"Red county\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ bluecty           : num [1:50083] 1 0 1 0 1 0 0 1 0 1 ...\n  ..- attr(*, \"label\")= chr \"Blue county\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ pwhite            : num [1:50083] 0.446 NA 0.936 0.888 0.759 ...\n  ..- attr(*, \"label\")= chr \"Proportion white within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ pblack            : num [1:50083] 0.5278 NA 0.0119 0.0108 0.1274 ...\n  ..- attr(*, \"label\")= chr \"Proportion black within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ page18_39         : num [1:50083] 0.318 NA 0.276 0.279 0.442 ...\n  ..- attr(*, \"label\")= chr \"Proportion age 18-39 within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ ave_hh_sz         : num [1:50083] 2.1 NA 2.48 2.65 1.85 ...\n  ..- attr(*, \"label\")= chr \"Average household size within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2f\"\n $ median_hhincome   : num [1:50083] 28517 NA 51175 79269 40908 ...\n  ..- attr(*, \"label\")= chr \"Median household income within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ powner            : num [1:50083] 0.5 NA 0.722 0.92 0.416 ...\n  ..- attr(*, \"label\")= chr \"Proportion house owner within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ psch_atlstba      : num [1:50083] 0.325 NA 0.193 0.412 0.44 ...\n  ..- attr(*, \"label\")= chr \"Proportion who finished college within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ pop_propurban     : num [1:50083] 1 NA 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Proportion of population urban within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n\ndata %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(\n    response_rate = mean(gave),\n    avg_donation = mean(amount),\n    n = n()\n  )\n\n# A tibble: 2 × 4\n  treatment response_rate avg_donation     n\n      &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n1         0        0.0179        0.813 16687\n2         1        0.0220        0.967 33396\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\n\n\n\n\nBalance Test\n\n\n\n\n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n# Load required libraries\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Variables to test\nvars &lt;- c(\"mrm2\", \"freq\", \"years\")\n\n# Loop through each variable and perform t-test and regression\nfor (var in vars) {\n  cat(\"\\n==============================\\n\")\n  cat(\"Variable:\", var, \"\\n\")\n\n  # Remove missing values\n  df_clean &lt;- na.omit(data[, c(var, \"treatment\")])\n\n  # T-test\n  t_test &lt;- t.test(df_clean[[var]] ~ df_clean$treatment, var.equal = FALSE)\n  print(t_test)\n\n  # Linear regression\n  formula &lt;- as.formula(paste(var, \"~ treatment\"))\n  lm_model &lt;- lm(formula, data = df_clean)\n  print(summary(lm_model))\n}\n\n\n==============================\nVariable: mrm2 \n\n    Welch Two Sample t-test\n\ndata:  df_clean[[var]] by df_clean$treatment\nt = -0.11953, df = 33394, p-value = 0.9049\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.2381015  0.2107298\nsample estimates:\nmean in group 0 mean in group 1 \n       12.99814        13.01183 \n\n\nCall:\nlm(formula = formula, data = df_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.012  -9.012  -5.012   6.002 154.988 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.99814    0.09353 138.979   &lt;2e-16 ***\ntreatment    0.01369    0.11453   0.119    0.905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.08 on 50080 degrees of freedom\nMultiple R-squared:  2.851e-07, Adjusted R-squared:  -1.968e-05 \nF-statistic: 0.01428 on 1 and 50080 DF,  p-value: 0.9049\n\n\n==============================\nVariable: freq \n\n    Welch Two Sample t-test\n\ndata:  df_clean[[var]] by df_clean$treatment\nt = 0.11085, df = 33326, p-value = 0.9117\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.1998370  0.2237945\nsample estimates:\nmean in group 0 mean in group 1 \n       8.047342        8.035364 \n\n\nCall:\nlm(formula = formula, data = df_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n -8.035  -6.047  -4.035   1.953 209.965 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.04734    0.08821  91.231   &lt;2e-16 ***\ntreatment   -0.01198    0.10802  -0.111    0.912    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.39 on 50081 degrees of freedom\nMultiple R-squared:  2.455e-07, Adjusted R-squared:  -1.972e-05 \nF-statistic: 0.0123 on 1 and 50081 DF,  p-value: 0.9117\n\n\n==============================\nVariable: years \n\n    Welch Two Sample t-test\n\ndata:  df_clean[[var]] by df_clean$treatment\nt = 1.0909, df = 32401, p-value = 0.2753\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.04584866  0.16094698\nsample estimates:\nmean in group 0 mean in group 1 \n       6.135914        6.078365 \n\n\nCall:\nlm(formula = formula, data = df_clean)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.136 -4.136 -1.136  2.864 88.922 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.13591    0.04260 144.023   &lt;2e-16 ***\ntreatment   -0.05755    0.05217  -1.103     0.27    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.503 on 50080 degrees of freedom\nMultiple R-squared:  2.429e-05, Adjusted R-squared:  4.327e-06 \nF-statistic: 1.217 on 1 and 50080 DF,  p-value: 0.27\n\n\nTable 1 shows that the treatment and control groups were balanced on key baseline characteristics. That’s important because: 1. It confirms that random assignment worked. 2. It rules out the possibility that observed treatment effects are due to pre-existing differences.\n\n\n\n\n\n\n\n\n\nExperimental Results\n\n\n\n\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Load necessary libraries\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Calculate donation proportions\ndonation_props &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(prop_donated = mean(gave, na.rm = TRUE)) %&gt;%\n  mutate(group = ifelse(treatment == 1, \"Treatment\", \"Control\"))\n\n# Plot\nggplot(donation_props, aes(x = group, y = prop_donated, fill = group)) +\n  geom_bar(stat = \"identity\", width = 0.6, show.legend = FALSE) +\n  geom_text(aes(label = scales::percent(prop_donated, accuracy = 0.1)), \n            vjust = -0.5, size = 5) +\n  scale_fill_manual(values = c(\"Control\" = \"#87CEEB\", \"Treatment\" = \"#1E90FF\")) +\n  labs(\n    title = \"Proportion of People Who Donated\",\n    x = \"Group\",\n    y = \"Proportion Donated\"\n  ) +\n  scale_y_continuous(labels = scales::percent, limits = c(0, 0.05)) +  # Set limit if values are small\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 12),\n    axis.title = element_text(size = 14)\n  )\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Drop missing values\ndata_clean &lt;- na.omit(data[, c(\"gave\", \"treatment\")])\n\n# T-test\nt_test_result &lt;- t.test(gave ~ treatment, data = data_clean, var.equal = FALSE)\nprint(t_test_result)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by treatment\nt = -3.2095, df = 36577, p-value = 0.001331\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.006733310 -0.001627399\nsample estimates:\nmean in group 0 mean in group 1 \n     0.01785821      0.02203857 \n\n# Bivariate linear regression\nlm_result &lt;- lm(gave ~ treatment, data = data_clean)\nsummary(lm_result)\n\n\nCall:\nlm(formula = gave ~ treatment, data = data_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\n\nThe coefficient on treatment is the marginal effect (in latent index units) of being in the treatment group.\nA positive, significant coefficient supports the claim that the treatment increased the likelihood of donating.\n\n\n# Load necessary libraries\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Drop missing values for the relevant variables\ndata_clean &lt;- na.omit(data[, c(\"gave\", \"treatment\")])\n\n# Run the probit regression\nprobit_model &lt;- glm(gave ~ treatment, family = binomial(link = \"probit\"), data = data_clean)\n\n# View the summary\nsummary(probit_model)\n\n\nCall:\nglm(formula = gave ~ treatment, family = binomial(link = \"probit\"), \n    data = data_clean)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.10014    0.02332 -90.074  &lt; 2e-16 ***\ntreatment    0.08678    0.02788   3.113  0.00185 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nThe treatment effect is positive and statistically significant (p ≈ 0.0019).\nThis supports Table 3, Column 1 of the paper: being assigned to treatment increases the probability of donating — in latent terms.\nThe latent index increase of 0.087 suggests a meaningful shift in underlying propensity to donate.\n\n\n\n\n\n\n\n\n\n\nDifferences between Match Rates\n\n\n\n\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Filter to only treatment group and relevant variables\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# Create subsets by match ratio\ngave_1to1 &lt;- subset(data_match, ratio == 1)$gave\ngave_2to1 &lt;- subset(data_match, ratio == 2)$gave\ngave_3to1 &lt;- subset(data_match, ratio == 3)$gave\n\n# T-tests\nt_test_2vs1 &lt;- t.test(gave_2to1, gave_1to1, var.equal = FALSE)\nt_test_3vs1 &lt;- t.test(gave_3to1, gave_1to1, var.equal = FALSE)\n\n# Print results\nt_test_2vs1\n\n\n    Welch Two Sample t-test\n\ndata:  gave_2to1 and gave_1to1\nt = 0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001942773  0.005711275\nsample estimates:\n mean of x  mean of y \n0.02263338 0.02074912 \n\nt_test_3vs1\n\n\n    Welch Two Sample t-test\n\ndata:  gave_3to1 and gave_1to1\nt = 1.015, df = 22215, p-value = 0.3101\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001847501  0.005816051\nsample estimates:\n mean of x  mean of y \n0.02273340 0.02074912 \n\n\nThis supports the authors comment 1. The existence of a match offer boosts giving. 2. But increasing the generosity of the match (from 1:1 to 2:1 or 3:1) doesn’t significantly change donor behavior.\n\n# Load required library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Filter treatment group and non-missing values\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# Create dummy variables for match ratios\ndata_match$ratio1 &lt;- ifelse(data_match$ratio == 1, 1, 0)\ndata_match$ratio2 &lt;- ifelse(data_match$ratio == 2, 1, 0)\ndata_match$ratio3 &lt;- ifelse(data_match$ratio == 3, 1, 0)\n\n# Option 1: Regression using dummy variables\nmodel_dummies &lt;- lm(gave ~ ratio1 + ratio2 + ratio3, data = data_match)\nsummary(model_dummies)\n\n\nCall:\nlm(formula = gave ~ ratio1 + ratio2 + ratio3, data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients: (1 not defined because of singularities)\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.022733   0.001392  16.335   &lt;2e-16 ***\nratio1      -0.001984   0.001968  -1.008    0.313    \nratio2      -0.000100   0.001968  -0.051    0.959    \nratio3             NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n# Option 2: Regression using ratio as a categorical variable\nmodel_categorical &lt;- lm(gave ~ factor(ratio), data = data_match)\nsummary(model_categorical)\n\n\nCall:\nlm(formula = gave ~ factor(ratio), data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.020749   0.001391  14.912   &lt;2e-16 ***\nfactor(ratio)2 0.001884   0.001968   0.958    0.338    \nfactor(ratio)3 0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n\n\nThe treatment group gave slightly more on average than the control group.\nHowever, the p-value (0.055) is just above the conventional 0.05 threshold for statistical significance.\nThis means that we can’t confidently say that treatment caused people to donate more — the observed difference could be due to chance.\n\n\n# Load the data\nlibrary(haven)\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to treatment group with non-missing values\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# 1. Raw response rate differences\nresponse_rates &lt;- tapply(data_match$gave, data_match$ratio, mean)\ndiff_2vs1_raw &lt;- response_rates[\"2\"] - response_rates[\"1\"]\ndiff_3vs2_raw &lt;- response_rates[\"3\"] - response_rates[\"2\"]\n\n# 2. Regression using factor(ratio)\nmodel &lt;- lm(gave ~ factor(ratio), data = data_match)\nsummary(model)\n\n\nCall:\nlm(formula = gave ~ factor(ratio), data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.020749   0.001391  14.912   &lt;2e-16 ***\nfactor(ratio)2 0.001884   0.001968   0.958    0.338    \nfactor(ratio)3 0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n# Differences from fitted model (1:1 is reference group)\ncoef_2vs1 &lt;- coef(model)[\"factor(ratio)2\"]\ncoef_3vs1 &lt;- coef(model)[\"factor(ratio)3\"]\ncoef_3vs2 &lt;- coef_3vs1 - coef_2vs1\n\n# Print everything\nprint(response_rates)\n\n         1          2          3 \n0.02074912 0.02263338 0.02273340 \n\ncat(\"Raw Diff 2:1 - 1:1 =\", diff_2vs1_raw, \"\\n\")\n\nRaw Diff 2:1 - 1:1 = 0.001884251 \n\ncat(\"Raw Diff 3:1 - 2:1 =\", diff_3vs2_raw, \"\\n\")\n\nRaw Diff 3:1 - 2:1 = 0.000100024 \n\ncat(\"Fitted Diff 2:1 - 1:1 =\", coef_2vs1, \"\\n\")\n\nFitted Diff 2:1 - 1:1 = 0.001884251 \n\ncat(\"Fitted Diff 3:1 - 2:1 =\", coef_3vs2, \"\\n\")\n\nFitted Diff 3:1 - 2:1 = 0.000100024 \n\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\n\n\n\n\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Drop missing values\ndata_clean &lt;- na.omit(data[, c(\"amount\", \"treatment\")])\n\n# T-test\nt_test_result &lt;- t.test(amount ~ treatment, data = data_clean, var.equal = FALSE)\nprint(t_test_result)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = -1.9183, df = 36216, p-value = 0.05509\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.310555423  0.003344493\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8132678       0.9668733 \n\n# Bivariate linear regression\nlm_result &lt;- lm(amount ~ treatment, data = data_clean)\nsummary(lm_result)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data_clean)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n\n\nThe mean donation in the treatment group is slightly higher than in the control group (~$0.15 more). 2.But the p-value from both tests is just above 0.05, which means the difference is not statistically significant at the 95% confidence level.\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to donors only (amount &gt; 0)\ndata_donors &lt;- subset(data, amount &gt; 0 & !is.na(treatment))\n\n# T-test\nt_test_donors &lt;- t.test(amount ~ treatment, data = data_donors, var.equal = FALSE)\nprint(t_test_donors)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = 0.58461, df = 557.46, p-value = 0.559\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -3.937240  7.274027\nsample estimates:\nmean in group 0 mean in group 1 \n       45.54027        43.87188 \n\n# Linear regression (donation amount ~ treatment)\nlm_donors &lt;- lm(amount ~ treatment, data = data_donors)\nsummary(lm_donors)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data_donors)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n\n\nThe t-test and linear regression both likely returned a non-significant difference in donation amounts between the treatment and control groups.\nThe regression coefficient for treatment was probably close to 0 or negative, and not statistically significant.\n\n\n# Load necessary library\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only those who donated\ndata_donors &lt;- subset(data, amount &gt; 0 & !is.na(treatment))\n\n# Calculate group means\ngroup_means &lt;- data_donors %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(mean_amount = mean(amount))\n\n# Plot for Treatment group\nggplot(data_donors[data_donors$treatment == 1, ], aes(x = amount)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\") +\n  geom_vline(xintercept = group_means$mean_amount[group_means$treatment == 1], \n             color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Donation Amounts - Treatment Group\", x = \"Donation Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Plot for Control group\nggplot(data_donors[data_donors$treatment == 0, ], aes(x = amount)) +\n  geom_histogram(binwidth = 2, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = group_means$mean_amount[group_means$treatment == 0], \n             color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Donation Amounts - Control Group\", x = \"Donation Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\n\n\n\n\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\n\n\n\n\n\n\n\nLaw of Large Numbers\n\n\n\n\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only positive donations\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Simulate: 100,000 draws from control, 10,000 from treatment\nsim_control &lt;- sample(donations_control, size = 100000, replace = TRUE)\nsim_treatment &lt;- sample(donations_treatment, size = 10000, replace = TRUE)\n\n# Sample 10,000 control values to match treatment sample\nsim_control_sample &lt;- sample(sim_control, size = 10000, replace = FALSE)\n\n# Calculate differences\ndifferences &lt;- sim_treatment - sim_control_sample\n\n# Cumulative average\ncumulative_avg_diff &lt;- cumsum(differences) / seq_along(differences)\n\n# True difference in means\ntrue_diff &lt;- mean(donations_treatment) - mean(donations_control)\n\n# Plot\nplot(cumulative_avg_diff, type = \"l\", col = \"blue\", lwd = 2,\n     main = \"Cumulative Average of Simulated Differences\",\n     xlab = \"Simulation Index\", ylab = \"Cumulative Average Difference\")\nabline(h = true_diff, col = \"red\", lty = 2)\nlegend(\"bottomright\", legend = c(\"Cumulative Average\", \"True Difference\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\n\n\n\n\n\n\n\n\nYes — the cumulative average approaches the true difference in means. This illustrates the Law of Large Numbers: with more data, your estimate becomes more stable and closer to the true population value. It also reinforces the power of randomization and repeated sampling — even if individual draws are noisy, the average across many replicates becomes reliable.\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to positive donation amounts\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Function to simulate 1000 average differences at a given sample size\nsimulate_diffs &lt;- function(n, reps = 1000) {\n  replicate(reps, {\n    sample_control &lt;- sample(donations_control, size = n, replace = TRUE)\n    sample_treat &lt;- sample(donations_treatment, size = n, replace = TRUE)\n    mean(sample_treat) - mean(sample_control)\n  })\n}\n\n# Sample sizes to test\nsample_sizes &lt;- c(50, 200, 500, 1000)\ndiffs_list &lt;- lapply(sample_sizes, simulate_diffs)\n\n# Plot the histograms\npar(mfrow = c(2, 2))  # 2x2 layout\nfor (i in 1:4) {\n  hist(diffs_list[[i]], main = paste(\"Sample Size =\", sample_sizes[i]),\n       xlab = \"Avg Difference (Treatment - Control)\", col = \"skyblue\", border = \"black\")\n  abline(v = 0, col = \"red\", lwd = 2, lty = 2)\n}\n\n\n\n\n\n\n\n\nAt small sample sizes (e.g., 50):\nThe distribution of average differences is wide and noisy. The red line at zero often appears in the middle — suggesting a high chance of not detecting a difference. As sample size increases (200 → 500 → 1000):\nThe distribution becomes narrower. It starts to center away from zero, and zero moves to the tail of the distribution. This reflects increasing statistical power — you’re more likely to detect the true effect as the sample grows.\n\n\n\n#Done"
  },
  {
    "objectID": "blog/AB_Testing/index1.html#experimental-results",
    "href": "blog/AB_Testing/index1.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\n\n\n\n\n\nCharitable Contribution Made\n\n\n\n\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Load necessary libraries\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Calculate donation proportions\ndonation_props &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(prop_donated = mean(gave, na.rm = TRUE)) %&gt;%\n  mutate(group = ifelse(treatment == 1, \"Treatment\", \"Control\"))\n\n# Plot\nggplot(donation_props, aes(x = group, y = prop_donated, fill = group)) +\n  geom_bar(stat = \"identity\", width = 0.6, show.legend = FALSE) +\n  geom_text(aes(label = scales::percent(prop_donated, accuracy = 0.1)), \n            vjust = -0.5, size = 5) +\n  scale_fill_manual(values = c(\"Control\" = \"#87CEEB\", \"Treatment\" = \"#1E90FF\")) +\n  labs(\n    title = \"Proportion of People Who Donated\",\n    x = \"Group\",\n    y = \"Proportion Donated\"\n  ) +\n  scale_y_continuous(labels = scales::percent, limits = c(0, 0.05)) +  # Set limit if values are small\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 12),\n    axis.title = element_text(size = 14)\n  )\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Drop missing values\ndata_clean &lt;- na.omit(data[, c(\"gave\", \"treatment\")])\n\n# T-test\nt_test_result &lt;- t.test(gave ~ treatment, data = data_clean, var.equal = FALSE)\nprint(t_test_result)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by treatment\nt = -3.2095, df = 36577, p-value = 0.001331\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.006733310 -0.001627399\nsample estimates:\nmean in group 0 mean in group 1 \n     0.01785821      0.02203857 \n\n# Bivariate linear regression\nlm_result &lt;- lm(gave ~ treatment, data = data_clean)\nsummary(lm_result)\n\n\nCall:\nlm(formula = gave ~ treatment, data = data_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\n\nThe coefficient on treatment is the marginal effect (in latent index units) of being in the treatment group.\nA positive, significant coefficient supports the claim that the treatment increased the likelihood of donating.\n\n\n# Load necessary libraries\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Drop missing values for the relevant variables\ndata_clean &lt;- na.omit(data[, c(\"gave\", \"treatment\")])\n\n# Run the probit regression\nprobit_model &lt;- glm(gave ~ treatment, family = binomial(link = \"probit\"), data = data_clean)\n\n# View the summary\nsummary(probit_model)\n\n\nCall:\nglm(formula = gave ~ treatment, family = binomial(link = \"probit\"), \n    data = data_clean)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.10014    0.02332 -90.074  &lt; 2e-16 ***\ntreatment    0.08678    0.02788   3.113  0.00185 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nThe treatment effect is positive and statistically significant (p ≈ 0.0019).\nThis supports Table 3, Column 1 of the paper: being assigned to treatment increases the probability of donating — in latent terms.\nThe latent index increase of 0.087 suggests a meaningful shift in underlying propensity to donate.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Filter to only treatment group and relevant variables\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# Create subsets by match ratio\ngave_1to1 &lt;- subset(data_match, ratio == 1)$gave\ngave_2to1 &lt;- subset(data_match, ratio == 2)$gave\ngave_3to1 &lt;- subset(data_match, ratio == 3)$gave\n\n# T-tests\nt_test_2vs1 &lt;- t.test(gave_2to1, gave_1to1, var.equal = FALSE)\nt_test_3vs1 &lt;- t.test(gave_3to1, gave_1to1, var.equal = FALSE)\n\n# Print results\nt_test_2vs1\n\n\n    Welch Two Sample t-test\n\ndata:  gave_2to1 and gave_1to1\nt = 0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001942773  0.005711275\nsample estimates:\n mean of x  mean of y \n0.02263338 0.02074912 \n\nt_test_3vs1\n\n\n    Welch Two Sample t-test\n\ndata:  gave_3to1 and gave_1to1\nt = 1.015, df = 22215, p-value = 0.3101\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001847501  0.005816051\nsample estimates:\n mean of x  mean of y \n0.02273340 0.02074912 \n\n\nThis supports the authors comment 1. The existence of a match offer boosts giving. 2. But increasing the generosity of the match (from 1:1 to 2:1 or 3:1) doesn’t significantly change donor behavior.\n\n# Load required library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Filter treatment group and non-missing values\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# Create dummy variables for match ratios\ndata_match$ratio1 &lt;- ifelse(data_match$ratio == 1, 1, 0)\ndata_match$ratio2 &lt;- ifelse(data_match$ratio == 2, 1, 0)\ndata_match$ratio3 &lt;- ifelse(data_match$ratio == 3, 1, 0)\n\n# Option 1: Regression using dummy variables\nmodel_dummies &lt;- lm(gave ~ ratio1 + ratio2 + ratio3, data = data_match)\nsummary(model_dummies)\n\n\nCall:\nlm(formula = gave ~ ratio1 + ratio2 + ratio3, data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients: (1 not defined because of singularities)\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.022733   0.001392  16.335   &lt;2e-16 ***\nratio1      -0.001984   0.001968  -1.008    0.313    \nratio2      -0.000100   0.001968  -0.051    0.959    \nratio3             NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n# Option 2: Regression using ratio as a categorical variable\nmodel_categorical &lt;- lm(gave ~ factor(ratio), data = data_match)\nsummary(model_categorical)\n\n\nCall:\nlm(formula = gave ~ factor(ratio), data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.020749   0.001391  14.912   &lt;2e-16 ***\nfactor(ratio)2 0.001884   0.001968   0.958    0.338    \nfactor(ratio)3 0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n\n\nThe treatment group gave slightly more on average than the control group.\nHowever, the p-value (0.055) is just above the conventional 0.05 threshold for statistical significance.\nThis means that we can’t confidently say that treatment caused people to donate more — the observed difference could be due to chance.\n\n\n# Load the data\nlibrary(haven)\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to treatment group with non-missing values\ndata_match &lt;- subset(data, treatment == 1 & !is.na(ratio) & !is.na(gave))\n\n# 1. Raw response rate differences\nresponse_rates &lt;- tapply(data_match$gave, data_match$ratio, mean)\ndiff_2vs1_raw &lt;- response_rates[\"2\"] - response_rates[\"1\"]\ndiff_3vs2_raw &lt;- response_rates[\"3\"] - response_rates[\"2\"]\n\n# 2. Regression using factor(ratio)\nmodel &lt;- lm(gave ~ factor(ratio), data = data_match)\nsummary(model)\n\n\nCall:\nlm(formula = gave ~ factor(ratio), data = data_match)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.020749   0.001391  14.912   &lt;2e-16 ***\nfactor(ratio)2 0.001884   0.001968   0.958    0.338    \nfactor(ratio)3 0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n# Differences from fitted model (1:1 is reference group)\ncoef_2vs1 &lt;- coef(model)[\"factor(ratio)2\"]\ncoef_3vs1 &lt;- coef(model)[\"factor(ratio)3\"]\ncoef_3vs2 &lt;- coef_3vs1 - coef_2vs1\n\n# Print everything\nprint(response_rates)\n\n         1          2          3 \n0.02074912 0.02263338 0.02273340 \n\ncat(\"Raw Diff 2:1 - 1:1 =\", diff_2vs1_raw, \"\\n\")\n\nRaw Diff 2:1 - 1:1 = 0.001884251 \n\ncat(\"Raw Diff 3:1 - 2:1 =\", diff_3vs2_raw, \"\\n\")\n\nRaw Diff 3:1 - 2:1 = 0.000100024 \n\ncat(\"Fitted Diff 2:1 - 1:1 =\", coef_2vs1, \"\\n\")\n\nFitted Diff 2:1 - 1:1 = 0.001884251 \n\ncat(\"Fitted Diff 3:1 - 2:1 =\", coef_3vs2, \"\\n\")\n\nFitted Diff 3:1 - 2:1 = 0.000100024 \n\n\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\n\n\n\n\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Drop missing values\ndata_clean &lt;- na.omit(data[, c(\"amount\", \"treatment\")])\n\n# T-test\nt_test_result &lt;- t.test(amount ~ treatment, data = data_clean, var.equal = FALSE)\nprint(t_test_result)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = -1.9183, df = 36216, p-value = 0.05509\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.310555423  0.003344493\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8132678       0.9668733 \n\n# Bivariate linear regression\nlm_result &lt;- lm(amount ~ treatment, data = data_clean)\nsummary(lm_result)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data_clean)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n\n\nThe mean donation in the treatment group is slightly higher than in the control group (~$0.15 more). 2.But the p-value from both tests is just above 0.05, which means the difference is not statistically significant at the 95% confidence level.\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to donors only (amount &gt; 0)\ndata_donors &lt;- subset(data, amount &gt; 0 & !is.na(treatment))\n\n# T-test\nt_test_donors &lt;- t.test(amount ~ treatment, data = data_donors, var.equal = FALSE)\nprint(t_test_donors)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = 0.58461, df = 557.46, p-value = 0.559\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -3.937240  7.274027\nsample estimates:\nmean in group 0 mean in group 1 \n       45.54027        43.87188 \n\n# Linear regression (donation amount ~ treatment)\nlm_donors &lt;- lm(amount ~ treatment, data = data_donors)\nsummary(lm_donors)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data_donors)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n\n\nThe t-test and linear regression both likely returned a non-significant difference in donation amounts between the treatment and control groups.\nThe regression coefficient for treatment was probably close to 0 or negative, and not statistically significant.\n\n\n# Load necessary library\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only those who donated\ndata_donors &lt;- subset(data, amount &gt; 0 & !is.na(treatment))\n\n# Calculate group means\ngroup_means &lt;- data_donors %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(mean_amount = mean(amount))\n\n# Plot for Treatment group\nggplot(data_donors[data_donors$treatment == 1, ], aes(x = amount)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\") +\n  geom_vline(xintercept = group_means$mean_amount[group_means$treatment == 1], \n             color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Donation Amounts - Treatment Group\", x = \"Donation Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Plot for Control group\nggplot(data_donors[data_donors$treatment == 0, ], aes(x = amount)) +\n  geom_histogram(binwidth = 2, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = group_means$mean_amount[group_means$treatment == 0], \n             color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Donation Amounts - Control Group\", x = \"Donation Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\n\n\n\n\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\n\n\n\n\n\n\n\nLaw of Large Numbers\n\n\n\n\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only positive donations\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Simulate: 100,000 draws from control, 10,000 from treatment\nsim_control &lt;- sample(donations_control, size = 100000, replace = TRUE)\nsim_treatment &lt;- sample(donations_treatment, size = 10000, replace = TRUE)\n\n# Sample 10,000 control values to match treatment sample\nsim_control_sample &lt;- sample(sim_control, size = 10000, replace = FALSE)\n\n# Calculate differences\ndifferences &lt;- sim_treatment - sim_control_sample\n\n# Cumulative average\ncumulative_avg_diff &lt;- cumsum(differences) / seq_along(differences)\n\n# True difference in means\ntrue_diff &lt;- mean(donations_treatment) - mean(donations_control)\n\n# Plot\nplot(cumulative_avg_diff, type = \"l\", col = \"blue\", lwd = 2,\n     main = \"Cumulative Average of Simulated Differences\",\n     xlab = \"Simulation Index\", ylab = \"Cumulative Average Difference\")\nabline(h = true_diff, col = \"red\", lty = 2)\nlegend(\"bottomright\", legend = c(\"Cumulative Average\", \"True Difference\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\n\n\n\n\n\n\n\n\nYes — the cumulative average approaches the true difference in means. This illustrates the Law of Large Numbers: with more data, your estimate becomes more stable and closer to the true population value. It also reinforces the power of randomization and repeated sampling — even if individual draws are noisy, the average across many replicates becomes reliable.\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n# Load necessary library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to positive donation amounts\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Function to simulate 1000 average differences at a given sample size\nsimulate_diffs &lt;- function(n, reps = 1000) {\n  replicate(reps, {\n    sample_control &lt;- sample(donations_control, size = n, replace = TRUE)\n    sample_treat &lt;- sample(donations_treatment, size = n, replace = TRUE)\n    mean(sample_treat) - mean(sample_control)\n  })\n}\n\n# Sample sizes to test\nsample_sizes &lt;- c(50, 200, 500, 1000)\ndiffs_list &lt;- lapply(sample_sizes, simulate_diffs)\n\n# Plot the histograms\npar(mfrow = c(2, 2))  # 2x2 layout\nfor (i in 1:4) {\n  hist(diffs_list[[i]], main = paste(\"Sample Size =\", sample_sizes[i]),\n       xlab = \"Avg Difference (Treatment - Control)\", col = \"skyblue\", border = \"black\")\n  abline(v = 0, col = \"red\", lwd = 2, lty = 2)\n}\n\n\n\n\n\n\n\n\nAt small sample sizes (e.g., 50):\nThe distribution of average differences is wide and noisy. The red line at zero often appears in the middle — suggesting a high chance of not detecting a difference. As sample size increases (200 → 500 → 1000):\nThe distribution becomes narrower. It starts to center away from zero, and zero moves to the tail of the distribution. This reflects increasing statistical power — you’re more likely to detect the true effect as the sample grows."
  },
  {
    "objectID": "blog/AB_Testing/index1.html#simulation-experiment",
    "href": "blog/AB_Testing/index1.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n# Load necessary library\nlibrary(haven)\n\n# Load the data\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to only positive donations\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Simulate: 100,000 draws from control, 10,000 from treatment\nsim_control &lt;- sample(donations_control, size = 100000, replace = TRUE)\nsim_treatment &lt;- sample(donations_treatment, size = 10000, replace = TRUE)\n\n# Sample 10,000 control values to match treatment sample\nsim_control_sample &lt;- sample(sim_control, size = 10000, replace = FALSE)\n\n# Calculate differences\ndifferences &lt;- sim_treatment - sim_control_sample\n\n# Cumulative average\ncumulative_avg_diff &lt;- cumsum(differences) / seq_along(differences)\n\n# True difference in means\ntrue_diff &lt;- mean(donations_treatment) - mean(donations_control)\n\n# Plot\nplot(cumulative_avg_diff, type = \"l\", col = \"blue\", lwd = 2,\n     main = \"Cumulative Average of Simulated Differences\",\n     xlab = \"Simulation Index\", ylab = \"Cumulative Average Difference\")\nabline(h = true_diff, col = \"red\", lty = 2)\nlegend(\"bottomright\", legend = c(\"Cumulative Average\", \"True Difference\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\n\n\n\n\n\n\n\n\nYes — the cumulative average approaches the true difference in means. This illustrates the Law of Large Numbers: with more data, your estimate becomes more stable and closer to the true population value. It also reinforces the power of randomization and repeated sampling — even if individual draws are noisy, the average across many replicates becomes reliable.\n\n\nCentral Limit Theorem\n\n# Load necessary library\nlibrary(haven)\n\n# Load the dataset\ndata &lt;- read_dta(\"/Users/siddharthamysore/sid_site/blog/AB_Testing/karlan_list_2007.dta\")\n\n# Filter to positive donation amounts\ndonations_control &lt;- subset(data, treatment == 0 & amount &gt; 0)$amount\ndonations_treatment &lt;- subset(data, treatment == 1 & amount &gt; 0)$amount\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Function to simulate 1000 average differences at a given sample size\nsimulate_diffs &lt;- function(n, reps = 1000) {\n  replicate(reps, {\n    sample_control &lt;- sample(donations_control, size = n, replace = TRUE)\n    sample_treat &lt;- sample(donations_treatment, size = n, replace = TRUE)\n    mean(sample_treat) - mean(sample_control)\n  })\n}\n\n# Sample sizes to test\nsample_sizes &lt;- c(50, 200, 500, 1000)\ndiffs_list &lt;- lapply(sample_sizes, simulate_diffs)\n\n# Plot the histograms\npar(mfrow = c(2, 2))  # 2x2 layout\nfor (i in 1:4) {\n  hist(diffs_list[[i]], main = paste(\"Sample Size =\", sample_sizes[i]),\n       xlab = \"Avg Difference (Treatment - Control)\", col = \"skyblue\", border = \"black\")\n  abline(v = 0, col = \"red\", lwd = 2, lty = 2)\n}\n\n\n\n\n\n\n\n\nAt small sample sizes (e.g., 50):\nThe distribution of average differences is wide and noisy. The red line at zero often appears in the middle — suggesting a high chance of not detecting a difference. As sample size increases (200 → 500 → 1000):\nThe distribution becomes narrower. It starts to center away from zero, and zero moves to the tail of the distribution. This reflects increasing statistical power — you’re more likely to detect the true effect as the sample grows."
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html",
    "href": "blog/Homework_2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n# Load necessary library\nlibrary(readr)\n\n# Read in the Blueprinty dataset\nblueprinty &lt;- read_csv(\"/Users/siddharthamysore/sid_site/blog/Homework_2/blueprinty.csv\")\nairbnb &lt;- read_csv(\"/Users/siddharthamysore/sid_site/blog/Homework_2/airbnb.csv\") \n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\n\n# Create a labeled version of customer status for readability\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(customer_status = ifelse(iscustomer == 1, \"Customer\", \"Non-customer\"))\n\n# Prettier histogram\nggplot(blueprinty, aes(x = patents, fill = customer_status)) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"white\", alpha = 0.85) +\n  scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\")) +\n  labs(\n    title = \"Distribution of Patent Counts by Customer Status\",\n    x = \"Number of Patents (Last 5 Years)\",\n    y = \"Number of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)\n\n# Load the data\nblueprinty &lt;- read.csv(\"blueprinty.csv\")\n\n# Calculate mean patents by customer status\ngrouped_means &lt;- blueprinty %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_patents = round(mean(patents, na.rm = TRUE), 2))\n\n# Pretty table output\nkable(grouped_means, col.names = c(\"Customer Status\", \"Mean Patents\"))\n\n\n\n\nCustomer Status\nMean Patents\n\n\n\n\n0\n3.47\n\n\n1\n4.13"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#blueprinty-case-study",
    "href": "blog/Homework_2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n# Load necessary library\nlibrary(readr)\n\n# Read in the Blueprinty dataset\nblueprinty &lt;- read_csv(\"/Users/siddharthamysore/sid_site/blog/Homework_2/blueprinty.csv\")\nairbnb &lt;- read_csv(\"/Users/siddharthamysore/sid_site/blog/Homework_2/airbnb.csv\") \n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\n\n# Create a labeled version of customer status for readability\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(customer_status = ifelse(iscustomer == 1, \"Customer\", \"Non-customer\"))\n\n# Prettier histogram\nggplot(blueprinty, aes(x = patents, fill = customer_status)) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"white\", alpha = 0.85) +\n  scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\")) +\n  labs(\n    title = \"Distribution of Patent Counts by Customer Status\",\n    x = \"Number of Patents (Last 5 Years)\",\n    y = \"Number of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)\n\n# Load the data\nblueprinty &lt;- read.csv(\"blueprinty.csv\")\n\n# Calculate mean patents by customer status\ngrouped_means &lt;- blueprinty %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_patents = round(mean(patents, na.rm = TRUE), 2))\n\n# Pretty table output\nkable(grouped_means, col.names = c(\"Customer Status\", \"Mean Patents\"))\n\n\n\n\nCustomer Status\nMean Patents\n\n\n\n\n0\n3.47\n\n\n1\n4.13"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#airbnb-case-study",
    "href": "blog/Homework_2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#observation",
    "href": "blog/Homework_2/hw2_questions.html#observation",
    "title": "Poisson Regression Examples",
    "section": "Observation:",
    "text": "Observation:\n\nCustomers tend to have more patents: Firms using Blueprinty are more frequently found in the 4–6 patent range, while non-customers cluster around 2–4 patents.\nVisual difference is clear: The histogram shows a visible rightward shift in patent counts for customers compared to non-customers.\nCaution is needed: This difference could be influenced by other factors like firm age or region, not just Blueprinty usage.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Part A: Region distribution by customer status\nblueprinty %&gt;%\n  mutate(customer_status = ifelse(iscustomer == 1, \"Customer\", \"Non-customer\")) %&gt;%\n  count(region, customer_status) %&gt;%\n  ggplot(aes(x = region, y = n, fill = customer_status)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\")) +\n  labs(title = \"Region Distribution by Customer Status\",\n       x = \"Region\",\n       y = \"Number of Firms\",\n       fill = \"Customer Status\") +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n\n\n\n\n\n\n# Part B: Age comparison by customer status\nggplot(blueprinty, aes(x = factor(iscustomer, labels = c(\"Non-customer\", \"Customer\")), y = age, fill = factor(iscustomer))) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\")) +\n  labs(title = \"Firm Age by Customer Status\",\n       x = \"Customer Status\",\n       y = \"Firm Age (Years)\",\n       fill = \"Customer Status\") +\n  theme_minimal(base_size = 14) +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n\n\n\n\n\n\n# Mean age by customer status\nblueprinty %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_age = mean(age)) %&gt;%\n  mutate(Customer_Status = ifelse(iscustomer == 1, \"Customer\", \"Non-customer\"))\n\n# A tibble: 2 × 3\n  iscustomer mean_age Customer_Status\n       &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1          0     26.1 Non-customer   \n2          1     26.9 Customer"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#observation-1",
    "href": "blog/Homework_2/hw2_questions.html#observation-1",
    "title": "Poisson Regression Examples",
    "section": "Observation",
    "text": "Observation\n\nRegional differences: Customers are more concentrated in the Northeast region, indicating that Blueprinty’s adoption varies by geography and may be influenced by regional factors such as innovation density or marketing reach.\nAge differences: Customers tend to be slightly older firms on average, which may affect both their patenting behavior and their likelihood of adopting Blueprinty’s software.\n\n\nEstimation of Simple Poisson Model\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nLikelihood for Poisson Distribution\nLet ( Y_1, Y_2, , Y_n ) be independent observations from a Poisson distribution with mean ( ). The likelihood function is:\n\\[\nL(\\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!} = e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]"
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#log-likelihood-for-poisson-function",
    "href": "blog/Homework_2/hw2_questions.html#log-likelihood-for-poisson-function",
    "title": "Poisson Regression Examples",
    "section": "Log likelihood for Poisson Function",
    "text": "Log likelihood for Poisson Function\n\n# Define the log-likelihood function for Poisson\npoisson_log_likelihood &lt;- function(lambda, Y) {\n  n &lt;- length(Y)\n  sum_Y &lt;- sum(Y)\n  logL &lt;- -n * lambda + sum_Y * log(lambda) - sum(lgamma(Y + 1))\n  return(logL)\n}\n\n\nlibrary(ggplot2)\n\n# Define the log-likelihood function\npoisson_log_likelihood &lt;- function(lambda, Y) {\n  n &lt;- length(Y)\n  sum_Y &lt;- sum(Y)\n  logL &lt;- -n * lambda + sum_Y * log(lambda) - sum(lgamma(Y + 1))\n  return(logL)\n}\n\n# Generate values of lambda\nlambda_vals &lt;- seq(1, 7, by = 0.1)\n\n# Compute log-likelihood values\nloglik_vals &lt;- sapply(lambda_vals, function(l) poisson_log_likelihood(lambda = l, Y = blueprinty$patents))\n\n# Create a data frame for plotting\nll_df &lt;- data.frame(\n  lambda = lambda_vals,\n  loglik = loglik_vals\n)\n\n# Find the lambda that maximizes the log-likelihood\nmle_lambda &lt;- lambda_vals[which.max(loglik_vals)]\n\n# Prettier ggplot version\nggplot(ll_df, aes(x = lambda, y = loglik)) +\n  geom_line(color = \"#1f77b4\", size = 1.2) +\n  geom_vline(xintercept = mle_lambda, linetype = \"dashed\", color = \"red\", size = 1) +\n  labs(\n    title = \"Log-Likelihood of Poisson Model\",\n    subtitle = paste(\"Maximum at λ ≈\", round(mle_lambda, 2)),\n    x = expression(lambda),\n    y = \"Log-Likelihood\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\nDeriving the MLE for the Poisson Model\nLet ( Y_1, Y_2, , Y_n ) be independent observations where ( Y_i () ). The log-likelihood function is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^n \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n= -n\\lambda + \\left( \\sum_{i=1}^n Y_i \\right) \\log \\lambda - \\sum_{i=1}^n \\log(Y_i!)\n\\]\nTake the derivative with respect to ( ) and set it equal to zero:\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = -n + \\frac{1}{\\lambda} \\sum_{i=1}^n Y_i = 0\n\\]\nSolving for ( ):\n\\[\n-n + \\frac{1}{\\lambda} \\sum_{i=1}^n Y_i = 0\n\\quad \\Rightarrow \\quad\n\\lambda = \\frac{1}{n} \\sum_{i=1}^n Y_i = \\bar{Y}\n\\]\nConclusion: The maximum likelihood estimate of ( ) is the sample mean ( {Y} ), which makes intuitive sense because the Poisson distribution’s mean is ( ).\n\n\nNumerically Estimating λ using optim()\n\n# Negative log-likelihood (since optim() minimizes)\nneg_log_likelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(Inf)  # avoid log(0) or negative lambda\n  -poisson_log_likelihood(lambda, Y)\n}\n\n# Run optimization\noptim_result &lt;- optim(\n  par = 2,  # initial guess for lambda\n  fn = neg_log_likelihood,\n  Y = blueprinty$patents,\n  method = \"Brent\",\n  lower = 0.01,\n  upper = 10\n)\n\n# Display MLE of lambda\noptim_result$par\n\n[1] 3.684667\n\n\n\n\nEstimation of Poisson Regression Model\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nLog-Likelihood for Poisson Regression Model\n\n# Poisson regression log-likelihood function\npoisson_regression_loglik &lt;- function(beta, Y, X) {\n  eta &lt;- X %*% beta                 # linear predictor\n  lambda &lt;- exp(eta)               # inverse link: exp\n  logL &lt;- sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n  return(logL)\n}\n\n\n\nEstimate Poisson Regression Coefficients with optim()\n\nlibrary(dplyr)\n\n# 1. Prepare design matrix X and response Y\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(\n    age2 = age^2,\n    region = factor(region),  # Ensure it's a factor\n    region = relevel(region, ref = \"Southwest\")  # Reference category\n  )\n\n# Create model matrix: intercept, age, age^2, region dummies, customer\nX &lt;- model.matrix(~ age + age2 + region + iscustomer, data = blueprinty)\nY &lt;- blueprinty$patents\n\n# 2. Define negative log-likelihood function for use in optim()\nneg_loglik &lt;- function(beta, Y, X) {\n  eta &lt;- X %*% beta\n  lambda &lt;- exp(eta)\n  -sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n}\n\n# 3. Estimate beta using optim()\ninit_beta &lt;- rep(0, ncol(X))  # Start with zeros\nfit &lt;- optim(\n  par = init_beta,\n  fn = neg_loglik,\n  Y = Y,\n  X = X,\n  method = \"BFGS\",\n  hessian = TRUE\n)\n\n# 4. Extract coefficients and standard errors\nbeta_hat &lt;- fit$par\nhessian &lt;- fit$hessian\nse &lt;- sqrt(diag(solve(hessian)))  # Invert Hessian to get variance-covariance\n\n# 5. Create and display a table of results\n\n\n# Load knitr for pretty tables\nlibrary(knitr)\n\n# Create and print nicely formatted coefficient table\ncoef_table &lt;- data.frame(\n  Term = colnames(X),\n  Estimate = round(beta_hat, 4),\n  Std_Error = round(se, 4)\n)\n\nkable(coef_table, caption = \"Poisson Regression Coefficients and Standard Errors\")\n\n\nPoisson Regression Coefficients and Standard Errors\n\n\nTerm\nEstimate\nStd_Error\n\n\n\n\n(Intercept)\n-0.1257\n0.1108\n\n\nage\n0.1155\n0.0064\n\n\nage2\n-0.0022\n0.0001\n\n\nregionMidwest\n-0.0234\n0.0472\n\n\nregionNortheast\n-0.0247\n0.0392\n\n\nregionNorthwest\n-0.0349\n0.0498\n\n\nregionSouth\n-0.0055\n0.0494\n\n\niscustomer\n0.0606\n0.0321\n\n\n\n\n\n\n\nVerifying Results with glm()\n\n# Fit Poisson regression using glm()\nglm_model &lt;- glm(\n  patents ~ age + I(age^2) + region + iscustomer,\n  family = poisson(link = \"log\"),\n  data = blueprinty\n)\n\n# Summary of results\nsummary(glm_model)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(link = \"log\"), data = blueprinty)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.458344   0.182720  -2.508   0.0121 *  \nage              0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)        -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionMidwest   -0.050576   0.047198  -1.072   0.2839    \nregionNortheast -0.021406   0.038479  -0.556   0.5780    \nregionNorthwest -0.068151   0.049875  -1.366   0.1718    \nregionSouth      0.005985   0.048741   0.123   0.9023    \niscustomer       0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\nInterpretation of Poisson Regression Results\n\nCustomer Effect: The coefficient for iscustomer is positive, suggesting that firms using Blueprinty’s software have a higher expected number of patents, holding all other variables constant.\nFirm Age: The positive coefficient for age and negative coefficient for age² imply a nonlinear relationship, where patent activity increases with age up to a point, then slightly declines.\nRegional Differences: Some regional coefficients (e.g., Northeast, Midwest) are slightly negative compared to the reference group (Southwest), indicating lower expected patent counts in those regions, although the effects are modest.\nModel Fit: The signs, magnitudes, and standard errors from glm() closely match the custom MLE estimates, validating your implementation.\n\n\n\nEstimating the Effect of Blueprinty’s Software on Patents\n\n# Create counterfactual and treatment versions of the dataset\nX_0 &lt;- blueprinty\nX_0$iscustomer &lt;- 0\n\nX_1 &lt;- blueprinty\nX_1$iscustomer &lt;- 1\n\n# Predict number of patents using fitted glm model\ny_pred_0 &lt;- predict(glm_model, newdata = X_0, type = \"response\")\ny_pred_1 &lt;- predict(glm_model, newdata = X_1, type = \"response\")\n\n# Difference in predicted outcomes\neffect_vec &lt;- y_pred_1 - y_pred_0\naverage_effect &lt;- mean(effect_vec)\n\n# Display average predicted difference\naverage_effect\n\n[1] 0.7927681\n\n\nThe model estimates that using Blueprinty’s software increases the expected number of patents by approximately 0.79 patents per user, on average."
  },
  {
    "objectID": "blog/Homework_2/hw2_questions.html#airbnb-case-study-modeling-number-of-bookings-via-review-counts",
    "href": "blog/Homework_2/hw2_questions.html#airbnb-case-study-modeling-number-of-bookings-via-review-counts",
    "title": "Poisson Regression Examples",
    "section": "Airbnb Case Study: Modeling Number of Bookings via Review Counts",
    "text": "Airbnb Case Study: Modeling Number of Bookings via Review Counts\n\n# Load Airbnb data\nlibrary(readr)\nlibrary(dplyr)\n\n# Filter to keep relevant variables and drop rows with NAs\nairbnb_clean &lt;- airbnb %&gt;%\n  select(number_of_reviews, room_type, bathrooms, bedrooms, price,\n         review_scores_cleanliness, review_scores_location, \n         review_scores_value, instant_bookable) %&gt;%\n  na.omit()\n\n# Check dimensions after cleaning\ndim(airbnb_clean)\n\n[1] 30160     9\n\n\n\nExploratory Data Analysis\n\nlibrary(ggplot2)\n\n# Distribution of number of reviews\nggplot(airbnb_clean, aes(x = number_of_reviews)) +\n  geom_histogram(binwidth = 5, fill = \"#2c7fb8\", color = \"white\") +\n  labs(title = \"Distribution of Number of Reviews\",\n       x = \"Number of Reviews\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Boxplot of reviews by room type\nggplot(airbnb_clean, aes(x = room_type, y = number_of_reviews)) +\n  geom_boxplot(fill = \"#7fcdbb\") +\n  labs(title = \"Number of Reviews by Room Type\",\n       x = \"Room Type\", y = \"Number of Reviews\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nFit Poisson Regression Model\n\n# Fit Poisson regression model\nairbnb_model &lt;- glm(number_of_reviews ~ room_type + bathrooms + bedrooms +\n                      price + review_scores_cleanliness +\n                      review_scores_location + review_scores_value +\n                      instant_bookable,\n                    data = airbnb_clean, family = poisson(link = \"log\"))\n\n# View summary\nsummary(airbnb_model)\n\n\nCall:\nglm(formula = number_of_reviews ~ room_type + bathrooms + bedrooms + \n    price + review_scores_cleanliness + review_scores_location + \n    review_scores_value + instant_bookable, family = poisson(link = \"log\"), \n    data = airbnb_clean)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                3.572e+00  1.600e-02 223.215  &lt; 2e-16 ***\nroom_typePrivate room     -1.453e-02  2.737e-03  -5.310 1.09e-07 ***\nroom_typeShared room      -2.519e-01  8.618e-03 -29.229  &lt; 2e-16 ***\nbathrooms                 -1.240e-01  3.747e-03 -33.091  &lt; 2e-16 ***\nbedrooms                   7.494e-02  1.988e-03  37.698  &lt; 2e-16 ***\nprice                     -1.436e-05  8.303e-06  -1.729   0.0838 .  \nreview_scores_cleanliness  1.132e-01  1.493e-03  75.821  &lt; 2e-16 ***\nreview_scores_location    -7.680e-02  1.607e-03 -47.796  &lt; 2e-16 ***\nreview_scores_value       -9.153e-02  1.798e-03 -50.902  &lt; 2e-16 ***\ninstant_bookableTRUE       3.344e-01  2.889e-03 115.748  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 961626  on 30159  degrees of freedom\nResidual deviance: 936528  on 30150  degrees of freedom\nAIC: 1058014\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\nInterpretation of Results\n\nRoom Type: Listings that are private or shared rooms receive significantly fewer reviews than entire home/apartments, all else equal.\nBathrooms/Bedrooms: More bathrooms or bedrooms are associated with more reviews, though the effect size is modest.\nPrice: Higher prices are slightly negatively associated with number of reviews.\nReview Scores: Higher cleanliness, location, and value scores are positively associated with review counts, suggesting better guest experiences lead to more bookings.\nInstant Bookable: Listings that are instantly bookable receive more reviews, possibly due to convenience.\n\nThese results reflect how different listing features influence demand as measured by review activity."
  }
]